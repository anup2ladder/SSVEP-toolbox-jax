# Directory Layout
├── FeatureExtractorSSVEP/
│   ├── featureExtractorCCA.py
│   ├── featureExtractor.py
│   ├── featureExtractorMEC.py
│   ├── __init__.py
│   ├── featureExtractorMSI.py
│   ├── featureExtractorTemplateMatching.py

# Compiled Python Library

``` ./featureExtractorCCA.py
# featureExtractorCCA.py
"""
Feature extraction method using correlation coefficient analysis.
Chen, Xiaogang, et al. "Filter bank canonical correlation analysis
for implementing a high-speed SSVEP-based brain–computer interface.
Journal of neural engineering 12.4 (2015): 046008.
"""

# Import the definition of the parent class.  Make sure the file is in the
# working directory. 
from .featureExtractorTemplateMatching \
    import FeatureExtractorTemplateMatching

# Needed for basic matrix operations. 
import numpy as np

try:
    import cupy as cp
    cupy_available_global = True
except:
    cupy_available_global = False
    cp = np

class FeatureExtractorCCA(FeatureExtractorTemplateMatching):
    """Implementation of feature extraction using CCA"""
    
    def __init__(self):
        "Class constructor"            
        super().__init__()

        # If set to True, the feature extraction method only returns
        # the maximum correlation coefficient.  Otherwise, the class
        # returns k correlation coefficients, where k is the minimum of
        # of the template signal rank and signal rank.  Most studies use
        # only the maximum.  Thus, the default value is True. 
        self.max_correlation_only = True
     
    def setup_feature_extractor(
            self, 
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=None,
            max_correlation_only=True,
            embedding_dimension=0,
            delay_step=0,
            filter_order=0,
            filter_cutoff_low=0,
            filter_cutoff_high=0,
            voters_count=1,
            random_seed=0,
            use_gpu=False,
            max_batch_size=16,
            explicit_multithreading=0,
            samples_count=0):
        """
        Setup the feature extractor parameters CCA.
        
        Mandatory Parameters:
        -------------------------------------
        harmonics_count: The number of harmonics to be used in constructing
        the template signal.  This variable must be a positive integer 
        number (typically a value from 3 to 5).  
        
        targets_frequencies: The stimulation freqeuency of each target.  
        This must be a 1D array,  where the first element is the stimulation
        frequency of the first target, the second element is the stimulation
        frequency of the second target, and so on.  The length of this array
        indicates the number of targets.  The user must determine the 
        targets_frequencies but the number of targets (targets_count) is 
        extracted automatically from the length of targets_frequencies. 
        
        sampling_frequency: The sampling rate of the signal 
        (in samples per second).  It must be a real positive value. 
                
        Optional Parameters:
        --------------------        
        embedding_dimension: This is the dimension of time-delay embedding. 
        This must be a non-negative integer.  If set to zero, no time-delay
        embedding will be used.  If there are E electrodes and we set the 
        embedding_dimension to n, the class expands the input signal as if we
        had n*E channels.  The additional channels are generated by shift_left
        operator. The number of samples that we shift each signal is 
        controlled by delay_step.  Embedding delays truncates the signal. 
        Make sure the signal is long enough. 
        
        delay_step: The number of samples that are shifted for each delay
        embedding dimension.  For example, assume we have ten channels, 
        embedding_dimension is two, and delay_step is three.  In this case, the
        class creates 30 channels.  The first ten channels are the original
        signals coming from the ten electrodes.  The second ten signals are
        obtained by shifting the origianl signals by three samples.  The third
        ten signals are obtained by shifting the original signals by six 
        samples.  The signals are truncated accordingly. 
        
        filter_order: The order of the filter used for filtering signals before
        analysis.  If filter_order is zero (the default value), no filtering
        is performed.  Otherwise, the class creates a filter of order 
        filter_order.  This must be positive integer. 
        
        cutoff_frequency_low: The first cutoff frequency of the bandpass 
        filter.  This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        cutoff_frequency_high: The second cutoff frequency of the bandpass
        filter. This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        subbands: This is the primary way to instruct the classifier whether 
        to use filterbank or not.  The default value is None.  If set to None, 
        the classifier uses none-fitlerbank implementation.  To use
        filterbanks, subbands must be set to a 2D array, whith exactly two 
        columns.  Each row of this matrix defines a subband with two 
        frequencies provided in two columns.  The first column is the first
        cutoff frequency and the second column is the second cutoff frequency
        of that subband.  Filterbank filters the signal using a bandpass
        filter with these cutoff frequencies to obtain a new subband.  The
        number of rows in the matrix defines the number of subbands. All
        frequencies must be in Hz.  For each row, the second column must
        always be greater than the first column. 
        
        voters_count: The number of electrode-selections that are used for
        classification.  This must be a positive integer.  This is the 
        same as the number of voters.  If voters_count is larger that the 
        cardinality of the power set of the current selected electrodes, 
        then at least one combination is bound to happen more than once. 
        However, because the selection is random, even if voters_count is
        less than the cardinality of the power set, repettitions are still
        possible (although unlikely). If not specified or set to 1, no 
        voting will be used. 
        
        random_seed: This parameter control the seed for random selection 
        of electrodes.  This must be set to a non-negative integer.  The 
        default value is zero.
                
        use_gpu: When set to 'True,' the class uses a gpu to extract features.
        The host must be equipped with a CUDA-capable GPU.  When set to
        'False,' all processing will be on CPU. 
        
        max_batch_size: The maximum number of signals/channel selections
        that are processed in one batch.  Increasing this number improves
        parallelization at the expense of more memory requirement.  
        This must be a single positve integer. 
        
        explicit_multithreading: This parameter determines whether to use 
        explicit multithreading or not.  If set to a non-positive integer, 
        no multithreading will be used.  If set to a positive integer, the 
        class creates multiple threads to process signals/voters in paralle.
        The number of threads is the same as the value of this variable. 
        E.g., if set to 4, the class distributes the workload among four 
        threads.  Typically, this parameter should be the same as the number
        of cores the cput has, if multithreading is to be used. 
        Multithreading cannot be used when use_gpu is set to True.
        If multithreading is set to a positive value while used_gpu is 
        set to True or vice versa, the classes raises an error and the 
        program terminates. 
        
        samples_count: If provided, the class performs precomputations that
        only depend on the number of samples, e.g., computing the template
        signal.  If not provided, the class does not perform precomputations.
        Instead, it does the computations once the input signal was provided 
        and the class learns the number of samples from the input signal. 
        Setting samples_count is highly recommended.  If the feaure extraction
        method is being used in loop (e.g., BCI2000 loop), setting this 
        parameter eliminates the need to compute the template matrix each
        time. It also helps the class to avoid other computations in each
        iteration. samples_count passed to this function must be the same 
        as the third dimension size of the signal passed to extract_features().
        If that is not the case, the template and input signal will have 
        different dimensions.  The class should issue an error in this case
        and terminate the execution. 
        """        
        self.build_feature_extractor(
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=subbands,           
            embedding_dimension=embedding_dimension,
            delay_step=delay_step,
            filter_order=filter_order,
            filter_cutoff_low=filter_cutoff_low,
            filter_cutoff_high=filter_cutoff_high,
            voters_count=voters_count,
            random_seed=random_seed,
            use_gpu=use_gpu,
            max_batch_size=max_batch_size,
            explicit_multithreading=explicit_multithreading,
            samples_count=samples_count)
            
        self.max_correlation_only = max_correlation_only
                        
    def get_features(self, device):
        """Extract features using CCA"""   
        # Get the current batch of data        
        signal = self.get_current_data_batch()        
        correlations = self.canonical_correlation_reduced(signal, device)  
        xp = self.get_array_module(correlations)
        
        if self.max_correlation_only == True:
            correlations = xp.max(correlations, axis=-1)
                   
        batch_size = self.channel_selection_info_bundle[1]
        signals_count = correlations.shape[0]//batch_size
        
        # De-bundle the results.
        correlations = xp.reshape(correlations, (
            signals_count,
            batch_size,
            self.targets_count,            
            -1))
        
        if self.max_correlation_only == True:
            features = correlations
        
        else:                
            # De-bundle the results.
            features = xp.zeros((
                signals_count,
                batch_size,
                self.targets_count,
                self.features_count),
                dtype=np.float32)
        
            features[:, :, :, :correlations.shape[-1]] = correlations
        
        return features
    
    def get_features_multithreaded(self, signal):
        """Extract MSI features from a single signal"""        
        # Make sure signal is 3D
        signal -= np.mean(signal, axis=-1)[:, None]
        signal = signal[None, :, :] 
            
        if self.max_correlation_only == False:
            self.features_count = np.min((
                self.electrodes_count, 2*self.harmonics_count))
            
        correlations = self.canonical_correlation_reduced(signal, device=0)  

        if self.max_correlation_only == True:
            correlations = np.max(correlations, axis=-1)
                       
        # De-bundle the results.
        correlations = np.reshape(correlations, (
            1, 
            1,
            1,
            self.targets_count,            
            -1))
        
        if self.max_correlation_only == True:
            features = correlations
        
        else:                
            # De-bundle the results.
            features = np.zeros((
                1, 
                1,
                1,
                self.targets_count,               
                self.features_count),
                dtype=np.float32)
        
            features[:, :, :, :, :correlations.shape[-1]] = correlations
        
        return features
        
    def canonical_correlation_reduced(self, signal, device):
        """Compute the canonical correlation between X and Y. """         
        q_template = self.q_template_handle[device]
        xp = self.get_array_module(q_template)    
         
        signal = xp.transpose(signal, axes=(0, 2, 1))      
        
        # q_signal = xp.linalg.qr(signal[0])[0]
        # q_signal = xp.expand_dims(q_signal, axis=0)

        if self.explicit_multithreading > 0:
            q_signal = np.linalg.qr(signal[0])[0]
            q_signal = np.expand_dims(q_signal, axis=0)
        else:   
            q_signal = xp.linalg.qr(signal)[0]
            # q_signal = xp.expand_dims(q_signal, axis=0)
            # q_signal = self.qr_decomposition(signal)
        q_signal = xp.transpose(q_signal, axes=(0, 2, 1))
                     
        product = xp.matmul(
            q_signal[:, None, :, :], q_template[None, :, :, :])
        
        r = xp.linalg.svd(product, full_matrices=False, compute_uv=False)
        r[r>1] = 1
        r[r<0] = 0
        
        return r
    
    def qr_decomposition(self, X):
        """QR Decomposition based on Schwarz Rutishauser algorithm"""
        # Credit: Arthur V. Ratz (towardsdatascience.com)
        # Current implementation is slow on GPU.
        # Because we launch too many small kernels.
        xp = self.get_array_module(X)
        Q = X
        ns, m, n = X.shape
        R = xp.zeros((ns, n, n), dtype=xp.float32)
        
        for k in xp.arange(n):
            for i in xp.arange(k):
                Qt = Q[:, :, i]
                R[:, i, k] = xp.sum(xp.multiply(Qt, Q[:, :, k]), axis=1)
                product = xp.multiply(R[:, i, k][:, None], Q[:, :, i])
                Q[:, :, k] = Q[:, :, k] - product
                
            R[:, k, k] = xp.sum(xp.square(Q[:, :, k]), axis=-1)
            R[:, k, k] = xp.sqrt(R[:, k, k])
            Q[:, :, k] = xp.divide(Q[:, :, k], R[:, k, k][:, None])
            
        return -Q
                
    def perform_voting_initialization(self, device=0):
        """Perform initialization and precomputations common to all voters"""
        # Center data
        self.all_signals -= np.mean(self.all_signals, axis=-1)[:, :, None]     
        self.all_signals_handle = self.handle_generator(self.all_signals)
        rank = np.linalg.matrix_rank(self.all_signals)
        
        if any(rank < np.min(self.all_signals.shape[1:])):
            self.quit("Input signal is not full rank!  ")         
            
        if self.max_correlation_only == False:
            self.features_count = np.min((
                self.electrodes_count, 2*self.harmonics_count))
        
    def class_specific_initializations(self):
        """Perform necessary initializations"""
        # Perform some percomputations only in the first run.  
        # These computations only rely on the template signal and can thus
        # be pre-computed to improve performance. 
        self.compute_templates()  
        
        if self.samples_count == 1:
            self.quit("Signal is too short. Cannot compute canoncial "
                      + "correlations of a matrix with a single sample.")
            
        # Center the template signal. It should be already pretty much 
        # centered by if the cut-off does not align well with the end 
        # of period, we might get some non-zero weights. 
        self.template_signal -= np.mean(
            self.template_signal, axis=1)[:, None, :]
        
        # Q part of the QR decomposition
        self.q_template = np.zeros(
            self.template_signal.shape, dtype=np.float32)
        
        for i in np.arange(self.targets_count):        
            self.q_template[i] = np.linalg.qr(self.template_signal[i])[0]
            
        rank_template = np.linalg.matrix_rank(self.template_signal)
        
        if any(rank_template != 2*self.harmonics_count):
            self.quit("Template matrix is not full rank.")
         
        self.template_signal_handle = self.handle_generator(
            self.template_signal)
        
        self.q_template_handle = self.handle_generator(
            self.q_template)
               
    def get_current_data_batch(self):
        """Bundle all data so they can be processed toegher"""
        # Bundling helps increase GPU and CPU utilization. 
       
        # Extract bundle information. 
        # Helps with the code's readability. 
        batch_index = self.channel_selection_info_bundle[0]        
        batch_population = self.channel_selection_info_bundle[1]
        batch_electrodes_count = self.channel_selection_info_bundle[2]
        first_signal = self.channel_selection_info_bundle[3]
        last_signal = self.channel_selection_info_bundle[4]
        signals_count = last_signal - first_signal
        
        # Pre-allocate memory for the batch
        signal = np.zeros(
            (signals_count, batch_population,
             batch_electrodes_count, self.samples_count),
            dtype=np.float32)        
        
        selected_signals = self.all_signals_handle[0][first_signal:last_signal]
        
        for j in np.arange(batch_population):
            current_selection = self.channel_selections[batch_index]
            signal[:, j] = selected_signals[:, current_selection, :]
            batch_index += 1
                        
        signal = np.reshape(signal, (-1,) + signal.shape[2:])
          
        # Move the extracted batches to the device memory if need be. 
        if self.use_gpu == True:          
            signal = cp.asarray(signal)
            
        return signal
        
    @property
    def max_correlation_only(self):
        """Getter for max_correlation_only flag"""
        return self.__max_correlation_only
    
    @max_correlation_only.setter
    def max_correlation_only(self, flag):
        """Setter for max_correlation_only flag"""
        try:
            flag = bool(flag)
        except(ValueError, TypeError):
            self.quit("max_correlation_only flag must be Boolean.")
            
        self.__max_correlation_only = flag
        
```

``` ./featureExtractor.py
# featureExtractor.py
"""Definition of the class FeatureExtractor"""
import numpy as np
import sys
from scipy.signal import sosfiltfilt, butter
from multiprocessing import Pool

try:
    import cupy as cp
    cupy_available_global = True
except:
    cupy_available_global = False
    cp = np
    

class FeatureExtractor:
    """A parent class for all feature extraction methods"""
    
    # The message given to the user if all_signals is set to an invalid value.
    __all_signals_setup_guide = ("Input signals must be a 3D array with the"
        + "dimensions of (signals_count, electrodes_count, samples_count), "
        + "where signals_count represents the number of all signals to be "
        + "analyzed. If there is only one signal, then signals_count "
        + "must be set to 1 but the input signal must remain 3D. "
        + "electrodes_count is the number of electrodes, and samples_count "
        + "is the number of samples. Thus, the first dimension of the "
        + "input signal indexes the signals, the second dimension indexes "
        + "the electrodes, and the third dimension indexes the samples. ")
        
    __parameters_count_setup_guide = ("is not setup correctly. You are " 
        + "getting this error because the variable is either None or zero. "
        + "Accessing this parameter prior to its initialization causes an " 
        + "error. This parameter is inferred from all_signals. To remedy "
        + "this problem, set up the input signals (all_signals) first. ")
     
    __embedding_dimension_setup_guide = ("Delay embedding dimension is set "
        + "to zero but the delay_step is set to a non-zero value. Because "
        + "embedding_dimension variable is zero, the value of delay_step is "
        + "discarded. To avoid inadvartant problems, the classs issues a  "
        + "warning and terminates the executuion. If you want to use delay, "
        + "embedding set the embedding_dimension to a positive integer. If "
        + "you do not want to use delay embedding, set delay_step to zero. ")
    
    __delay_step_setup_guide = ("delay_step is set to zero while delay "
        + "embedding dimension is non-zero. A zero delay step makes delayed "
        + "signals to be similar to the non-delayed signal. Thus, including "
        + "them is pointless. If you want to use delay embedding, set "
        + "delay_step to a positive integer. If you do not want to use "
        + "delay embedding, set the embedding_dimension to zero. ")
        
    def __init__(self):
        """Setting all object attributes to valid initial values"""
        # All the signals that need to be processed.  This must always be a 3D
        # numpy array with dimensions equal to the [signals_count, 
        # electrodes_count, samples_count].  If there is only one signal to be
        # processed, the array must still be 3D with the size of the first 
        # dimension being 1.  If a 2D array is passed, the class issues an
		# error and terminates execution.
        self.all_signals = None 
        
        # Total number of signals.  This variable is extracted automatically 
        # from the first dimension of all_signals.  This must be always a 
        # natural number.  If there is only one signal (e.g., during an online 
        # analysis), this variable is set to 1.  During batch processing (e.g., 
        # offline analysis of a dataset), this variable is automatically set
        # to the number of signals to be processed. 
        self.signals_count = 0
        
        # The number of channels or electrodes.  This must be a natural number.
        # This variable is set automatically based on the second dimension of
        # variable all_signals. 
        self.electrodes_count = 0
        
        # The number of features each feature extractor generates. 
        # Must be a positive integer. 
        self.features_count = 1
                                  
        # This is the dimension of time-delay embedding. 
        # This must be a non-negative integer.  If set to zero, no time-dely
        # embedding will be used.
        # If there are E electrodes and we set the embedding_dimension to 
        # n, the class expands the input signal as if we had n*E channels. 
        # The additional channels are generated by shift_left operators. 
        # The number of samples that we shift each signal is 
        # controlled by delay_step.  Embedding delays truncates the signal. 
        # Make sure the signal is long enough. 
        self.embedding_dimension = 0
        self.delay_step = 0
        
        # The number of samples in each signal (i.e., signal length is seconds
        # times the sampling rate).  This variable is extracted automatically
        # from the last dimension of variable all_signals.  This variable must
        # always be a natural number.                 
        self.samples_count = 0
        
        # The order of the filter to be used for filtering signals.
        # This must be a single positive ineger.
        self.filter_order = 0
        
        # Low and high cutoff frequencies for the filter (in Hz). 
        # These must be real positive numbers. 
        self.cutoff_frequency_low = 0
        self.cutoff_frequency_high = 0
        
        # The sampling rate of the signal (in samples per second). 
        # It must be a real positive value. 
        self.sampling_frequency = 0
        
        # This must be a 2D array with size S by 2, where S is the 
        # number of subbands to decompose the signal to.  The first
        # and second elements in each row describe the first and second
        # cutoff frequencies in Hz of the bandpass filter that is used to 
        # create subbands.  The number of subbands is inferred implicitly
        # from the number of rows in this matrix. 
        self.subbands = None
        self.subbands_count = 1
        self.is_filterbank = False
        
        # The sos for all matrices that we use in the filterbank. 
        # Saving them enables us to compute filters only once. 
        # Thus, improving the performance. 
        self.sos_matrices = None
        
        # The number of electrode-selections that are used for
        # classification.  This is the same as the number of voters.  If
        # votersCount is larger that the cardinality of the power set of 
        # the current selected electrodes, then at least one combination is
        # bound to happen more than once.  However, because the selection is
        # random, even if that's not the case, repettitions are still
        # possible.  If unset or set to an invalid value, no voting will 
        # be used. 
        self.voters_count = 1
        
        # The seed for random number generator that controls the electrodes
        # selection for each classification.  Use this for re-producibility.
        self.random_seed = 0
        
        # The random channels (electrodes) that are used for extracting 
        # features.  If used with voting, this represent the channel-selection
        # of each voter.  If the class is set up to not use voting, this 
        # is ignored.  
        self.channel_selections = None
                
        # A variable to include other information about the current 
        # chanel selection, e.g., the number of selections in each batch,
        # the index of the first selection, etc. It can be a tuple if a class
        # needs more information. 
        self.channel_selection_info_bundle = 0
        
        # A Boolean flag to instruct whether to use GPU or not.  
        # When set to false, no GPU is used.  When set to True, a GPU is used. 
        self.use_gpu = False
               
        # The maximum number of signals/channel selections that are 
        # processed together.  Increasing the batch size helps with 
        # parallelization but it also increases memory requirements. 
        self.max_batch_size = 16
        
        # This parameter determines whether to use explicit multithreading
        # or not.  If set to a non-positive integer, no multithreading will
        # be used. If set to a positive integer, the class creates multiple
        # threads to process signals/voters in parallel.  The number of 
        # threads is the same as the value of this variable.  E.g., if
        # set to 4, the class distributes the workload among four threads. 
        # Typically, this parameter should be the same as the number of cores
        # the cpu has, if multithreading is to be used. 
        # Multithreading cannot be used when use_gpu is set to True.
        self.explicit_multithreading = 0
        
        # A falg variable that allows us to see if class-specific 
        # initializations are completed or not.  class-specific initialization
        # can be performed when the class is being set up provided that the
        # user provides the number of samples. If the user does not provide
        # the number of samples, the class cannot perform class-specific 
        # initializations during class set up. Instead, it waits for the 
        # user to call extract_features(data). The class then automatically
        # extracts the number of samples from data and performs class specific
        # initialization done. The latter option can have a negative impact
        # on the performance if extract_features(data) is being called 
        # in a loop or periodically (e.g., in BCI2000 loop).
        self.class_initialization_is_complete = False
        
        # The number of devices       
        if cupy_available_global == True:        
            self.devices_count = cp.cuda.runtime.getDeviceCount()
        else:
            self.devices_count = 0
            
    def build_feature_extractor(
            self, 
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=None,           
            embedding_dimension=0,
            delay_step=0,
            filter_order=0,
            filter_cutoff_low=0,
            filter_cutoff_high=0,
            voters_count=1,
            random_seed=0,
            use_gpu=False,
            max_batch_size=16,
            explicit_multithreading=0,
            samples_count=0):
        """Set up the parameters of the calss"""
        self.harmonics_count = harmonics_count
        self.targets_frequencies = targets_frequencies
        self.sampling_frequency = sampling_frequency
        self.subbands = subbands
        self.embedding_dimension = embedding_dimension
        self.delay_step = delay_step
        self.filter_order = filter_order
        self.cutoff_frequency_low = filter_cutoff_low
        self.cutoff_frequency_high = filter_cutoff_high        
        self.random_seed = random_seed
        self.voters_count = voters_count
        self.use_gpu = use_gpu
        self.max_batch_size = max_batch_size
        self.explicit_multithreading = explicit_multithreading
        
        # Embedding delays truncates the signal. 
        # Thus, samples count must be updated accordingly. 
        if samples_count != 0:
            samples_count -= self.embedding_dimension * self.delay_step
            
        self.samples_count = samples_count 
        self.construct_filters()
        
        # If samples_count is provided, 
        if samples_count > 0:
            self.class_specific_initializations()
            self.class_initialization_is_complete = True
                        
    def extract_features(self, all_signals):
        """
        Extract the features from all given signals.
        
        parameter
        ----------
        all_signals: This must a 3D numpy array with the size 
        [signals_count, electrodes_count, samples_count], where
        signals_count is the number of all signals in the dataset that need
        to be processed.  If there is only one signal (e.g., online analysis),
        then the first dimension 'must' be set to 1.  electrodes_count is the
        number of channels and samples_count is the number of samples.   

        returns
        ------
        all_features: This is a 5D numpy array.
        [signals, subbands, voters, targets, features]. 
        Starting from left, the first dimension indexes signals, 
        the second dimension indexes subbands, the third dimension indexes
        voters (i.e., channel selections), the fourth dimension indexes
        targets, and the last dimension indexes features. 
        For example, if the input signal (all_signals) has dimensions 
        [3, 15, 1000] and the classifier is set up to use a filter bank
        with 8 subbands, 64 different random channel selections, and 40
        targets, assuming that the class generates one feature per signal,
        all_features will have a shape of [3, 8, 64, 40, 1]. 
        If there is only one signal to be processed, then the first dimension
        will be 1.  If the feature extractor is non-filter bank, then the 
        second dimension will have a size of 1.  If no random channel 
        selection is set up (i.e., the number of voters is set to 1), 
        the class uses all electrodes and the third dimension will have a 
        size of 1.  If there is only one feature for each signal, then 
        the fifth dimension will have a size of 1.       
        """        
        
        # This calls the setter and ensures that the input
        # is properly shaped, i.e., it is a 3D numpy array. 
        # This also sets signals_count, electrodes_count,
        # and samples_count automatically by extracting 
        # the dimension sizes of all_signals.             
        self.all_signals = all_signals
                
        # Filter the signal (if the user has not specified a non-zero
        # filter order, this does nothing.)       
        self.bandpass_filter()
        
        # Create new signal by decomposing them according to the given 
        # subbands. Do nothing if is_filterbank flag is False. 
        self.decompose_signal()
        
        # Expand all_signals by adding delayed replica of it. 
        # If the embedding_dimension is zero, this function does nothing. 
        self.embed_time_delay()
                    
        # Randomly pick n channel selection if the classifier is set up to use
        # voting, where n is the same as self.voters_count.  Otherwise, create
        # a single channel selection by using all electrodes.
        self.select_channels()   
        
        # Some objects need to perform some pre-computations.
        # However, the type of pre-computations depends on the class.
        # Perform these computation only if not done so so far
        if self.class_initialization_is_complete == False:            
            self.class_specific_initializations()    
        
        # Process all signals using self.explicit_multithreading number of
        # threads
        if self.explicit_multithreading > 0:           
            self.use_gpu = False
            features = self.process_signals_multithreaded()
        else:        
            features = self.process_signals_platform_agnostic()       
        
        if self.use_gpu == True:
            cp.cuda.Stream.null.synchronize()         
        
        return features
   
    def get_features(self, device):
        """
        Extract features from signal based on the method used.
        This is an abstract method and should never be called. 
        """        
        # This method is abstract. It is implementation
        # depends on the actual feature extraction method.
        # All non-abstract classes, inhereting form this
        # class must implement this method. 
        pass
    
    def get_features_multithreaded(self, signal):
        """
        Extract features from signal based on the method used.
        This is an abstract method and should never be called. 
        """        
        # This method is abstract. It is implementation
        # depends on the actual feature extraction method.
        # All non-abstract classes, inhereting form this
        # class must implement this method. 
        pass
    
    def perform_voting_initialization(self, device=0):
        """
        Some voting operations need to be done only once.  This is a class
        dependent implementation.  Thu, the method needs to be made concrete 
        by each sub-class.  These intializations and precomputings can lead to 
        substantial speed ups.        
        """
        # Empty
        # Must be made concrete by the sub-class.
        pass
    
    def class_specific_initializations(self):
        """Perform necessary initializations"""
        # Abstract method        
        # Do nothing
        pass
    
    def process_signals_platform_agnostic(self):
        """Process signals on GPU or CPU depending on use_gpu flag"""
        # Perform pre-computations that are common for all voters.
        if self.use_gpu == True:
            device = 1
            xp = cp
        else:
            device = 0
            xp = np
            
        self.perform_voting_initialization(device)  

        features = xp.zeros(
            (self.signals_count, 
             self.voters_count, 
             self.targets_count,              
             self.features_count),
            dtype=xp.float32)  
                  
        batch_index = 0    
        
        # Get the number of electrodes in each channel selection
        selection_size = np.sum(self.channel_selections, axis=1)
        
        while batch_index < self.voters_count:
            current_electrodes_count = selection_size[batch_index]
            
            # How many selections have current_electrodes_count electrodes                                   
            current_size = np.sum(selection_size == current_electrodes_count)
            
            # If less than max_batch_size, select all channel selections
            # Otherwise, pick the first max_batch_size of them. 
            current_size = np.min((current_size, self.max_batch_size))
            
            # Save the batch information.  We later use these to extract 
            # the data of each batch. 
            self.channel_selection_info_bundle = [
                batch_index, current_size, current_electrodes_count, 0, 0]
            
            # Burn the picked selections so that they don't get selected again.
            selection_size[batch_index:batch_index+current_size] = -1
            
            signal_index = 0
            
            while signal_index < self.signals_count:
                last_signal_index = signal_index + self.max_batch_size
                
                last_signal_index = np.min(
                    (last_signal_index, self.signals_count)
                    )
                
                self.channel_selection_info_bundle[3] = signal_index
                self.channel_selection_info_bundle[4] = last_signal_index
                               
                # Extract features
                features[
                    signal_index:last_signal_index,
                    batch_index:batch_index+current_size] = (
                    self.get_features(device))
                                        
                signal_index = last_signal_index
                       
            batch_index += current_size
          
        if self.use_gpu == True:
            features = cp.asnumpy(features)
        
        features = np.reshape(features, (            
            self.subbands_count,
            self.signals_count//self.subbands_count,
            self.voters_count,
            self.targets_count,
            self.features_count))
        
        features = np.swapaxes(features, 0, 1)
        
        return features
    
    def process_signals_multithreaded(self):
        """Process each signal/voter in a thread"""
        tasks = np.arange(0, self.voters_count * self.signals_count)
   
        with Pool(self.explicit_multithreading) as pool:
            features = pool.map(
                self.extract_features_multithreaded, tasks)    
    
        features = np.array(features)              
        features = features[:, 0, 0, 0, :, :]
        
        # De-bundle voters from signals 
        features = np.reshape(
            features, 
            (self.voters_count, self.signals_count) + features.shape[1:]
            )
        
        features = np.transpose(features, axes=(1, 0, 2, 3))
        
        # De-bundle subbands from signals 
        original_signals_count = self.signals_count//self.subbands_count
        features = np.reshape(
            features,
            (self.subbands_count, original_signals_count) + features.shape[1:]
            )
        
        features = np.swapaxes(features, 0, 1)
               
        return features
    
    def extract_features_multithreaded(self, idx):
        """The feature extraction done by each thread"""        
        # Use thread ID to determine which signal and which electrode 
        # selection should the thread process.
        channel_index, signal_index = np.unravel_index(
            idx, (self.voters_count, self.signals_count))
                        
        # Select the signal and channels for this thread.
        signal = self.all_signals[
            signal_index,
            self.channel_selections[channel_index]]
        
        # Extract features
        features = self.get_features_multithreaded(signal)

        return features
                
    def handle_generator(self, to_copy):
        """Copy the input on every device and return handles for each device"""        
        if self.use_gpu == False:
            handle = [to_copy]
            return handle
        
        handle = []        
        to_copy = cp.asnumpy(to_copy)
        
        # The first handle is always the CPU handle
        handle.append(to_copy)
        
        if to_copy.dtype == cp.float64:
            to_copy = cp.float32(to_copy)
            
        elif to_copy.dtype == cp.complex128:
            to_copy = cp.complex64(to_copy)
                    
        # Copy the data in each device
        for i in range(self.devices_count):
            with cp.cuda.Device(i):
                handle.append(cp.asarray(to_copy))
                
        return handle
    
    def generate_random_selection(self):
        """Generate all random channel selections"""
        random_generator = np.random.default_rng(self.random_seed)
        
        random_channels_indexes = np.zeros(
            (self.voters_count, self.electrodes_count))
                
        # The while loop ensures there is no empty selection
        while True:
            
            # Flag all empty electrode selections
            rows_with_zeros_only = (
                np.sum(random_channels_indexes, axis=1) == 0)
            
            if not rows_with_zeros_only.any():
                break
                        
            # For each voter, draw logical indexes of the electrodes
            # the voter uses. 
            random_channels_indexes[rows_with_zeros_only] = (
                random_generator.choice(
                    [True, False],
                    size=(np.sum(rows_with_zeros_only), self.electrodes_count),
                    replace=True)
                )
        
        return random_channels_indexes
    
    def select_channels(self):
        """
        If the class is set to use voting, then perform as many random
        channel selections as the number of voters and save all randomly
        selected channels.  Otherwise, use all channels.
        """        
        if self.voters_count > 1:
            self.channel_selections = self.generate_random_selection()
        else:
             self.channel_selections = np.array([True]*self.electrodes_count)
             self.channel_selections = np.expand_dims(
                 self.channel_selections, axis=0)
             
        self.channel_selections = self.channel_selections.astype(bool)    
        
        # Sort channel selections based on the number of channels
        selection_size = np.sum(self.channel_selections, axis=1)
        sorted_index = np.argsort(selection_size)
        self.channel_selections = self.channel_selections[sorted_index]
     
    def embed_time_delay(self):
        """Expand signal by adding delayed replica of it.
        Include time-shifted copies of the signal. Each replica is 
        created by delaying all channels by delayStep samples. 
        The number of replica is determined by embeddingDimension."""                      
        # If no delay-embedding is requested by the user, do nothing.
        if self.embedding_dimension == 0:
            return
        
        # expanded_signal is the temporary growing signal, to which we add
        # delayed replica one by one. 
        expanded_signal = self.all_signals
        
        # For each embedding_dimension, add a delay replicate.
        for i in range(1, self.embedding_dimension+1):
            start_index = i * self.delay_step
            
            # The signal of zero that contains exactly as many zeros as needed
            # to keep the size of the signal the same after the shift. 
            # tail will be added at the end (right side) of the signal.
            tail = np.zeros(
                (self.signals_count, self.electrodes_count, i*self.delay_step),
                )
            
            # Shift the signal.  Append the right number of zeros for lost
            # samples.
            shifted_signal =  np.block(
                [self.all_signals[:, :, start_index:], tail]
                )
            
            # Stack values vertically.
            expanded_signal = np.block([[expanded_signal], [shifted_signal]])
        
        # Get rid of all zeros.  Effectively, we are truncating the signal.  
        expanded_signal = expanded_signal[
            :, :, :-self.delay_step*self.embedding_dimension]
        
        # Replace the input signal with the new delay embedded one.
        # Update all other paramters (e.g., electrodes count, samples count,
        # etc.)
        self.all_signals = expanded_signal
        
    def bandpass_filter(self):
        """Filter the given signal using Butterworth IIR filter"""        
        if self.filter_order == 0 or self.cutoff_frequency_high == 0:
            return
                            
        sos = butter(self.filter_order,
                     [self.cutoff_frequency_low, self.cutoff_frequency_high],
                     btype='bandpass',
                     output='sos',
                     fs=self.sampling_frequency)
        
        # Operate along the very last dimension of the array. 
        self.all_signals = sosfiltfilt(sos, self.all_signals, axis=-1)

    def quit(self, message="Error"):
        """A function to end the program in case of an error"""
        print("Error: " + message)
        sys.exit()
        
    def construct_filters(self):
        """Construct bandpass filters to be used in filterbank"""
        
        # If this is not filterbank, no filters needed.
        if self.is_filterbank == False:
            return 
        
        if self.filter_order == 0:
            message =("Filter order is zero. If you want to use "
                    + "filterbank, you must set both the filter order and "
                    + "subbands' cutoff frequencies.  If you do not want "
                    + "to  use FBCCA, do not pass subbands. ")
            self.quit(message)
            
        # For each given subband, create a filter with corresponding cutoff
        # frequencies. 
        all_sos = []
        
        for band in self.subbands:            
            sos = butter(self.filter_order,
                         band,
                         btype='bandpass',
                         output='sos',
                         fs=self.sampling_frequency)            
            all_sos.append(sos)
            
        self.sos_matrices = np.array(all_sos)
        
    def decompose_signal(self):
        """Decompose the signal into multiple bands"""        
        # If this is not filterbank, no decomposition is needed. 
        if self.is_filterbank == False:
            return

        # Run single-threaded
        if self.explicit_multithreading <= 0:
            all_subbands = []              
            
            for filter_sos in self.sos_matrices:            
                signal = sosfiltfilt(filter_sos, self.all_signals, axis=-1)
                all_subbands.append(signal)
        
        # Multi-threaded version
        else:        
            tasks = np.arange(self.subbands_count)
            
            with Pool(self.explicit_multithreading) as pool:
                all_subbands = pool.map(
                    self.decompose_signal_thread_task, tasks
                    )
        
        all_subbands = np.array(all_subbands)
        
        # Make sure data remains 3D. 
        all_subbands = np.reshape(
            all_subbands, (-1, all_subbands.shape[2], all_subbands.shape[3]))
        
        self.all_signals = all_subbands
    
    def decompose_signal_thread_task(self, task_index):
        """Decompose all signals for the subband indexed by task_index"""   
        # Multithreading over filters typically yields to better CPU 
        # utilization.
        filter_sos = self.sos_matrices[task_index]
        signal = sosfiltfilt(filter_sos, self.all_signals, axis=-1)                   
        return signal
            
    def get_array_module(self, array):
        """Return the module of the array even if failed to import cupy"""
        if self.use_gpu == False:
            return np
        else:
            return cp.get_array_module(array)
        
    def filterbank_standard_aggregator(self, features, a=1.25, b=0.25, axis=1):
        """
        Aggregates the features extracted by filterbank into a single number.
        Input features can be matrix with any shape but the subbands must
        be in the axis dimension. 
        """
        subbands_count = features.shape[axis]
        
        # If there is only one subband, there is no need for aggregation
        if subbands_count == 1:
            return features
        
        # Set up weights 
        n = 1 + np.arange(0, subbands_count)
        w = n**(-a) + b
        
        features = np.moveaxis(features, axis, -1)
        shape = features.shape
        features = np.reshape(features, (-1, subbands_count))
        features = np.multiply(w[None, :], np.square(features))
        features = np.reshape(features, shape)
        features = np.sum(features, axis=-1)
        features = np.expand_dims(features, axis=axis)
        return features
    
    def voting_classification_by_count(self, features):
        """
        Give each target a score based on number of votes.
        The input matrix must be 2D. The first dimension must index the
        channel selections while the second dim must index features. 
        """
        if features.ndim != 2:
            print("Could not get the features based on votes count. "
                  + "The input features matrix must be 2D. The first "
                  + "dimension must index the channel selections "
                  + "while the second dimension must index the features. "
                  + "Returning the input features without modifying it. "
                )

        winner_targets = np.argmax(features, axis=1)
        
        targets_count = features.shape[1]        
        features_based_on_votes = np.zeros((1, targets_count))
        
        for target in np.arange(targets_count):
            features_based_on_votes[0, target] = np.sum(
                winner_targets == target)
            
        return features_based_on_votes        
    
    @property
    def all_signals(self):
        """Getter function for all signals"""        
        if self.__all_signals is None:
            self.quit("all_signals is not properly set. " 
                      + self.__all_signals_setup_guide)
            
        return self.__all_signals
    
    @all_signals.setter
    def all_signals(self, all_signals):
        """Setter function for all signals""" 
        if all_signals is None:
            self.signals_count = 0
            self.electrodes_count = 0
            self.samples_count = 0
            self.__all_signals = None
            return
        
        try:
            all_signals = all_signals.astype(np.float32)
        except (ValueError, TypeError, AttributeError):
            self.quit(self.__all_signals_setup_guide)
            
        if all_signals.ndim != 3:
            self.quit(self.__all_signals_setup_guide)
            
        self.__all_signals = all_signals
        [self.signals_count, self.electrodes_count, self.samples_count] =\
            all_signals.shape 
    
    @property
    def signals_count(self):
        """Getter function for the number of signals"""        
        if self._signals_count == 0:
            self.quit("signlas_count " 
                      + self.__parameters_count_setup_guide 
                      + self.__all_signals_setup_guide)
            
        return self._signals_count
    
    @signals_count.setter
    def signals_count(self, signals_count):
        """Setter function for the number of signals"""
        error_message = "signals_count must be a non-negative integer. "   
        
        try:
            signals_count = int(signals_count)            
        except (ValueError, TypeError):
            self.quit(error_message)
        
        if signals_count < 0:
            self.quit(error_message)
                    
        self._signals_count = signals_count
        
    @property
    def electrodes_count(self):
        """Getter function for the number of electrodes"""
        if self._electrodes_count == 0:
            self.quit("electrodes_count " 
                      + self.__parameters_count_setup_guide 
                      + self.__all_signals_setup_guide)
            
        return self._electrodes_count

    @electrodes_count.setter
    def electrodes_count(self, electrodes_count):
        """Setter function for the number of electrodes"""
        error_message = "electrodes_count must be a positive integer. "        
        try:
            electrodes_count = int(electrodes_count)
        except (ValueError, TypeError):
            self.quit(error_message)
        
        if electrodes_count < 0:
            self.quit(error_message)
            
        self._electrodes_count = electrodes_count
        
    @property
    def features_count(self):
        """Getter function for class attribute features_count"""
        if self.__features_count <= 0:
            self.quit(
                "Trying to access features_count before initializing "
                + "it. ")
        return self.__features_count
    
    @features_count.setter
    def features_count(self, features_count):
        """Setter function for class attribute features_count"""
        error_message = ("feautres_count must be a positive integer. ")
        
        try:
            features_count = int(features_count)
        except(ValueError, TypeError):
            self.quit(error_message)
        
        if features_count <= 0:
            self.quit(error_message)
        
        self.__features_count = features_count
        
    @property
    def samples_count(self):
        """Getter function for the number of samples"""
        if self.__samples_count == 0:
            self.quit("samples_count " 
                      + self.__parameters_count_setup_guide 
                      + self.__all_signals_setup_guide)
            
        return self.__samples_count
   
    @samples_count.setter
    def samples_count(self, samples_count):
        """Setter function for the number of samples"""
        error_message = "samples_count count must be a positive integer. "
        
        try:
            samples_count = int(samples_count)
        except (ValueError, TypeError):
            self.quit(error_message)
            
        if samples_count < 0:
            self.quit(error_message)
            
        try:            
            if (self.__samples_count != 0 
                and samples_count != self._samples_count):
                self.quit(
                    "Inconsistent samples count. It seems that the new "
                    + "samples_count is non-zero and different from the "
                    + "current samples_count. This has probably happended "
                    + "because the samples_count variable set in "
                    + "setup_feature_extractor() is different from the size "
                    + "of the third dimension of signals provided in "
                    + "extract_features function. If you do not know the "
                    + "samples_count before having the signal consider "
                    + "removing samples_count option in extract_features "
                    + "function. If you know samples_count before having the "
                    + "signal, make sure it is consistent with "
                    + "dimensionality of the signal. ")
        except(AttributeError):
            self.__samples_count = samples_count    
            return
            
        self.__samples_count = samples_count       
        
    @property
    def embedding_dimension(self):
        """Getter function for attribute embedding_dimension"""
        if self.__embedding_dimension == 0 and self.__delay_step != 0:
            self.quit(self.__embedding_dimension_setup_guide)
            
        return self.__embedding_dimension
    
    @embedding_dimension.setter
    def embedding_dimension(self, embedding_dimension):
        """Setter function for attribute embedding_dimension"""
        error_message = "Delay embedding dim. must be a non-negative integer. "
        
        try:
            embedding_dimension = int(embedding_dimension)
        except(TypeError, ValueError):
            self.quit(error_message)
        
        if embedding_dimension < 0:
            self.quit(error_message)
            
        self.__embedding_dimension = embedding_dimension
        
    @property
    def delay_step(self):
        """Getter function for the attribute delay_step"""
        if self.__delay_step == 0 and self.__embedding_dimension != 0:
            self.quit(self.__delay_step_setup_guide)
            
        return self.__delay_step
    
    @delay_step.setter
    def delay_step(self, delay_step):
        """Setter function for attribute delay_step"""
        error_message = "Delay step size must be a positive integer. "
        
        try:
            delay_step = int(delay_step)
        except(ValueError, TypeError):
            self.quit(error_message)
            
        if delay_step < 0:
            self.quit(error_message)
            
        self.__delay_step = delay_step
        
    @property
    def filter_order(self):
        """Getter function for the attribute filter_order"""   
        if self._filter_order == 0 and (
                self.cutoff_frequency_low != 0 or
                self.cutoff_frequency_high != 0):
            self.quit("filter_order is zero but the cutoff frequencies are "
                      + "non-zero. To use bandpass filtering, set the "
                      + "filter_order to a positive integer. To not use "
                      + "bandpass filtering, set the cutoff frequencies to "
                      + "zero. ")
            
        return self._filter_order
    
    @filter_order.setter 
    def filter_order(self, filter_order):
        """Setter function for the attribute filter_order"""
        message = "The order of the filter must be a positive integer. "
        
        try:
            filter_order = int(filter_order)
        except(TypeError, ValueError):
            self.quit(message)
        
        if filter_order < 0:
            self.quit(message)                    
        
        self._filter_order = filter_order   
        
    @property
    def cutoff_frequency_low(self):
        """Getter function for the first cutoff frequency of the filter"""
        if self.__cutoff_frequency_low > self.__cutoff_frequency_high:
            self.quit("The first cutoff frequency cannot exceed the "
                      + "second one. ")
            
        return self.__cutoff_frequency_low
    
    @cutoff_frequency_low.setter
    def cutoff_frequency_low(self, cutoff_frequency):
        """Setter function for the first cutoff frequency of the filter"""
        message = "First cutoff frequency must be a positive real number. "
        
        try:
            cutoff_frequency = float(cutoff_frequency)
        except(ValueError, TypeError):
            self.quit(message)
        
        if cutoff_frequency < 0:
            self.quit(message)
        
        self.__cutoff_frequency_low = cutoff_frequency
            
    @property
    def cutoff_frequency_high(self):
        """Getter function for the second cutoff frequency of the filter"""
        if self.__cutoff_frequency_low > self.__cutoff_frequency_high:
            self.quit("The first cutoff frequency cannot exceed the "
                      + "second one. ")

        return self.__cutoff_frequency_high
    
    @cutoff_frequency_high.setter
    def cutoff_frequency_high(self, cutoff_frequency):
        """Setter function for the second cutoff frequency of the filter"""
        message = "Second cutoff frequency must be a positive real number. "
        
        try:
            cutoff_frequency = float(cutoff_frequency)
        except(ValueError, TypeError):
            self.quit(message)
        
        if cutoff_frequency < 0:
            self.quit(message)
        
        self.__cutoff_frequency_high = cutoff_frequency
        
    @property
    def sampling_frequency(self):
        """Getter function for sampling frequency"""
        if self.__sampling_frequency == 0:
            self.quit("Sampling frequency is not set. You can setup the "
                      + " sampling frequency using the sampling_frequency "
                      + "option of setup_feature_extractor method. ")
            
        return self.__sampling_frequency
    
    @sampling_frequency.setter
    def sampling_frequency(self, frequency):
        """Setter function for sampling frequency"""
        error_message = "Sampling frequency must a be a non-negative integer."
        
        try:
            frequency = float(frequency)
        except (TypeError, ValueError):
            self.quit(error_message)
        
        if frequency < 0:
            self.quit(error_message)           
            
        self.__sampling_frequency = frequency
        
    @property
    def sos_matrices(self):
        """Getter function for sos_matrices"""
        return self.__sos_matrices
    
    @sos_matrices.setter
    def sos_matrices(self, matrices):
        """Setter functioni for sos_matrices"""
        
        if matrices is None:
            self.__sos_matrices = 0
            return
        
        try:
            matrices = matrices.astype(float)
        except(ValueError, TypeError, AttributeError):
            self.quit("SOS matrix of the filter must be an array of floats.")
        
        self.__sos_matrices = matrices
        
    @property 
    def subbands(self):
        """Getter function for class attribute subbands"""        
        return self.__subbands
    
    @subbands.setter 
    def subbands(self, subbands):
        """Setter function for class attribute subbands"""
        message = ("Subbands must be a matrix of real nonnegative "
                + "numbers. The row corresponds to one subband. Each "
                + "row must have two column, where the first column is "
                + "the first cutoff frequency and the second column is "
                + "the second cutoff frequency. The entry in the second "
                + "must be larger than the entry in the first column "
                + "for each row.");
        
        if subbands is None:
            self.__subbands = None
            self.is_filterbank = False
            self.subbands_count = 1
            return
        
        # Chek if subbands is an array
        try:
            subbands = subbands.astype(np.float32)                
        except (ValueError, TypeError, AttributeError):
            self.quit(message)
        
        # subbands must be a 2D array
        if (subbands < 0).any() or subbands.ndim != 2:
            self.quit(message)
        
        # Check if all second cutoff frequencies are larger than first ones
        if (subbands[:, 0] >= subbands[:, 1]).any():
            self.quit("Second cutoff of the BPF must exceed the first one")
         
        # It is up to the user to make sure that cutoff frequencies are
        # consistent and make sense. 
        if np.sum(subbands) == 0:
            self.is_filterbank = False
        else:
            self.is_filterbank = True
        
        self.subbands_count = (subbands.shape)[0]
        self.__subbands = subbands
        
    
    @property
    def subbands_count(self):
        """Getter function for class attribute subbands_count"""
        return self.__subbands_count
    
    @subbands_count.setter 
    def subbands_count(self, subbands_count):
        """Setter function for the attribute subbands_count"""
        message = "The number of subbands must be a positive integer.  "
        
        if subbands_count is None:
            self.__subbands_count = 1
            return 
            
        try:
            subbands_count = int(subbands_count)
        except(ValueError, TypeError):
            self.quit(message)
            
        if subbands_count <= 0:
            self.quit(message)
            
        self.__subbands_count = subbands_count
        
    @property
    def voters_count(self):
        """Getter function for class attribute voters_count"""
        return self.__voters_count
    
    @voters_count.setter
    def voters_count(self, voters_count):
        """Setter function for the attribute voters_count"""
        message = "The number of voters must be a positive integer.  "
        
        if voters_count is None:
            self.__voters_count = 1
            return
            
        try:
            voters_count = int(voters_count)
        except(ValueError, TypeError):
            self.quit(message)
        
        if voters_count <= 0:
            self.quit(message)
        
        self.__voters_count = voters_count
        
    @property
    def random_seed(self):
        """Getter function for the attribute random_seed"""
        return self.__random_seed
    
    @random_seed.setter
    def random_seed(self, random_seed):
        """Setter function for the attribute random_seed"""        
        message = "random seed must be a non negative integer.  "
        
        if random_seed is None:
            self.__random_seed = 0
            return
            
        try:
            random_seed = int(random_seed)
        except(TypeError, ValueError):
            self.quit(message)
            
        if random_seed < 0:
            self.quit(message)
            
        self.__random_seed = random_seed
        
    @property
    def channel_selections(self):
        """Getter function for the attribute channel_selections"""
        return self.__channel_selections 
    
    @channel_selections.setter
    def channel_selections(self, channel_selections):
        """Setter function for the attribute channel_selections"""        
        message = ("channel selections is not set properly. Do not set "
        + "up this variable directly.  ")
        
        if channel_selections is None:
            self.__channel_selections = None
            return
            
        try:
            channel_selections = np.bool8(channel_selections)
        except(TypeError, ValueError):
            self.quit(message)

        self.__channel_selections = channel_selections
        
    @property
    def use_gpu(self):
        """Getter function for the attribute use_gpu"""
        return self.__use_gpu
    
    @use_gpu.setter
    def use_gpu(self, flag):
        """Setter function for the attribute use_gpu"""
        message = "Cannot set use_gpu. use_gpu flag must either True or False."
        
        try:
            flag = np.bool8(flag)
        except(TypeError, ValueError):
            self.quit(message)
            
        if flag.size != 1:
            self.quit(message)
            
        if flag == True and self.explicit_multithreading > 0:
            self.quit(
                "Cannot set use_gpu because explicit_multithreading is set "
                + "to a positive value.  use_gpu is not available when "
                + "multithreading is enabled. ")
            
        if flag == True and cupy_available_global == False:
            self.quit(
                "Cannot set use_gpu because the calss failed to import cupy. "
                + "This is probably because cupy is not installed correctly. "
                + "Or the host does not have any CUDA-capable device. "
                + "You can still run this code even if the host does not "
                + "a CUDA device or even if cupy is not installed. "
                + "But in order to do this, you should set use_gpu flag "
                + "in setup_feature_extractor() function to false. ")                
            
        self.__use_gpu = flag
        
    @property
    def max_batch_size(self):
        """Getter function for the attribute max_batch_size"""
        return self.__max_batch_size
    
    @max_batch_size.setter
    def max_batch_size(self, max_batch_size):
        """Setter function for the attribute max_batch_size"""
        message = "max_batch_size must be a positive integer.  "
        
        try:
            max_batch_size = np.int32(max_batch_size)
        except(ValueError, TypeError):
            self.quit(message)
            
        if max_batch_size.size != 1:
            self.quit(message)
            
        if max_batch_size <= 0:
            self.quit(message)
            
        self.__max_batch_size = max_batch_size
        
    @property
    def explicit_multithreading(self):
        """Getter function for the attribute explicit_multithreading"""
        return self.__explicit_multithreading
    
    @explicit_multithreading.setter
    def explicit_multithreading(self, cores_count):
        """Setter function for the attribute explicit_multithreading"""
        message = "explicit_multithreading must be an integer. "
        
        try:
            cores_count = np.int32(cores_count)
        except(ValueError, TypeError):
            self.quit(message)
            
        if cores_count.size != 1:
            self.quit(message)
            
        if cores_count < 0:
            cores_count = 0
            
        if cores_count >= 2048:
            self.quit(
                "explicit_multithreading is too large.  Typically " 
                + "this should be the same size as the number of cores " 
                + "or a number in that order. ")
        
        if self.use_gpu == True and cores_count > 0:
            self.quit(
                "Cannot set explicit_multithreading when use_gpu "
                + "is set to True.  Multithreading is not supported "
                + "when using GPUs. ")
            
        self.__explicit_multithreading = cores_count
```

``` ./featureExtractorMEC.py
# featureExtractorMEC.py
"""
Implementation of MEC feature extraction method
# Feature extraction method using minimum energy combination based on:
# Friman, Ola, Ivan Volosyak, and Axel Graser. "Multiple channel
# detection of steady-state visual evoked potentials for brain-computer
# interfaces." IEEE transactions on biomedical engineering 54.4 (2007).
"""
# Import the definition of the parent class.  Make sure the file is in the
# working directory.  
from .featureExtractorTemplateMatching \
    import FeatureExtractorTemplateMatching

# Needed for many matrix computations
import numpy as np

try:
    import cupy as cp
    cupy_available_global = True
except:
    cupy_available_global = False
    cp = np

# # A custom CUDA kernel for sum of products.
# @cp.fuse(kernel_name='sum_of_products')
# def sum_of_products(x, y):
#     return cp.sum(x * y, axis = -1)

class FeatureExtractorMEC(FeatureExtractorTemplateMatching):
    """Class of minimum energy combination feature extractor"""
    
    def __init__(self):
        """MEC feature extractor class constructor"""
        super().__init__()
        
        # The order of the AR model used for estimating noise energy.
        # This must be a single positive integer.  The order of the AR cannot
        # be more than the signal length. 
        self.ar_order = 15
        
        # The ratio of noise energy remained in the projected signal.
        # This must be a number between 0 and 1. 
        self.energy_ratio = 0.05
        
        # A temporary pre-computed value. 
        self.xplus = 0
        
        # The psudo-inverse of each [sine, cosine] pair for each harmonic
        self.sub_template_inverse = 0   
        
        if cupy_available_global == True:
            # CUDA kernel for computing sum of products. 
            self.sum_product_raw = cp.RawKernel(
                r'''
                extern "C" __global__
                void sum_product_raw(const float* const timeSeries,
                    const int batchSize, 
                    const int signalSize,
                    const int arraySize,
                    const int offset,
                    float* const results)
                {     
                  const int p = blockIdx.y;
                  const int batchId = blockIdx.x * blockDim.x + threadIdx.x;
                  const int index = batchId*batchSize - blockIdx.x*offset;
                  
                  if (index >= arraySize)
                      return;
                    
                  const int blockId = blockIdx.y * gridDim.x + blockIdx.x;
                  const int threadId = blockId * blockDim.x + threadIdx.x;                   

                  for (int i = 0; i < batchSize; i++) 
                  {
                      if (threadIdx.x*batchSize+i+p >= signalSize)
                          break;          
            
                       results[threadId] += 
                           timeSeries[index+i] * timeSeries[index+i+p];           
                  } // end for i
                  
                } // end kernel sum_product_raw
                ''', 'sum_product_raw')
       
    def setup_feature_extractor(
            self, 
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            ar_order=15,
            energy_ratio=0.05,
            embedding_dimension=0,
            delay_step=0,
            filter_order=0,
            filter_cutoff_low=0,
            filter_cutoff_high=0,
            subbands=None,
            voters_count=1,
            random_seed=0,
            use_gpu=False,
            max_batch_size=16,
            explicit_multithreading=0,
            samples_count=0):
        """
        Setup the feature extractor parameters (MEC).
        
        Mandatory Parameters:
        ---------------------
        harmonics_count: The number of harmonics to be used in constructing
        the template signal.  This variable must be a positive integer 
        number (typically a value from 3 to 5).  
        
        targets_frequencies: The stimulation freqeuency of each target.  
        This must be a 1D array,  where the first element is the stimulation
        frequency of the first target, the second element is the stimulation
        frequency of the second target, and so on.  The length of this array
        indicates the number of targets.  The user must determine the 
        targets_frequencies but the number of targets (targets_count) is 
        extracted automatically from the length of targets_frequencies. 
        
        sampling_frequency: The sampling rate of the signal 
        (in samples per second).  It must be a real positive value. 
        
        
        Optional Parameters:
        --------------------
        ar_order: This defines the order of the auto-regressive model, which
        is used to compute the expected energy of the noise.  This must be a
        positive integer. 
        
        energy_ratio: This define the ratio of the nuisance signal that is 
        kept in the projected channels.  This must be a real number between
        zero and one.  Reducing this ratio, reduces the energy of the nuisance
        signal but also leads to the loss of information. 
        
        embedding_dimension: This is the dimension of time-delay embedding. 
        This must be a non-negative integer.  If set to zero, no time-dely
        embedding will be used.  If there are E electrodes and we set the 
        embedding_dimension to n, the class expands the input signal as if we
        had n*E channels.  The additional channels are generated by shift_left
        operator.  The number of samples that we shift each signal is 
        controlled by delay_step.  Embedding delays truncates the signal. 
        Make sure the signal is long enough. 
        
        delay_step: The number of samples that are shifted for each delay
        embedding dimension.  For example, assume we have ten channels, 
        embedding_dimension is two, and delay_step is three.  In this case, the
        class creates 30 channels.  The first ten channels are the original
        signals coming from the ten electrodes.  The second ten signals are
        obtained by shifting the origianl signals by three samples.  The third
        ten signals are obtained by shifting the original signals by six 
        samples.  The signals are truncated accordingly. 
        
        filter_order: The order of the filter used for filtering signals before
        analysis.  If filter_order is zero (the default value), no filtering
        is performed.  Otherwise, the class creates a filter of order 
        filter_order.  This must be positive integer. 
        
        cutoff_frequency_low: The first cutoff frequency of the bandpass 
        filter.  This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        cutoff_frequency_high: The second cutoff frequency of the bandpass
        filter. This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        subbands: This is the primary way to instruct the classifier whether 
        to use filterbank or not.  The default value is None.  If set to None, 
        the classifier uses none-fitlerbank implementation.  To use
        filterbanks, subbands must be set to a 2D array, whith exactly two 
        columns.  Each row of this matrix defines a subband with two 
        frequencies provided in two columns.  The first column is the first
        cutoff frequency and the second column is the second cutoff frequency
        of that subband.  Filterbank filters the signal using a bandpass
        filter with these cutoff frequencies to obtain a new subband.  The
        number of rows in the matrix defines the number of subbands. All
        frequencies must be in Hz.  For each row, the second column must
        always be greater than the first column. 
        
        voters_count: The number of electrode-selections that are used for
        classification.  This must be a positive integer.  This is the 
        same as the number of voters.  If voters_count is larger that the 
        cardinality of the power set of the current selected electrodes, 
        then at least one combination is bound to happen more than once. 
        However, because the selection is random, even if voters_count is
        less than the cardinality of the power set, repettitions are still
        possible (although unlikely). If not specified or 1, no 
        voting will be used. 
        
        random_seed: This parameter control the seed for random selection 
        of electrodes.  This must be set to a non-negative integer.  The 
        default value is zero.
        
        use_gpu: When set to 'True,' the class uses a gpu to extract features.
        The host must be equipped with a CUDA-capable GPU.  When set to
        'False,' all processing will be on CPU. 
        
        max_batch_size: The maximum number of signals/channel selections
        that are processed in one batch.  Increasing this number improves
        parallelization at the expense of more memory requirement.  
        This must be a single positve integer. 
        
        explicit_multithreading: This parameter determines whether to use 
        explicit multithreading or not.  If set to a non-positive integer, 
        no multithreading will be used.  If set to a positive integer, the 
        class creates multiple threads to process signals/voters in paralle.
        The number of threads is the same as the value of this variable. 
        E.g., if set to 4, the class distributes the workload among four 
        threads.  Typically, this parameter should be the same as the number
        of cores the cput has, if multithreading is to be used. 
        Multithreading cannot be used when use_gpu is set to True.
        If multithreading is set to a positive value while used_gpu is 
        set to True or vice versa, the classes raises an error and the 
        program terminates. 
        
        samples_count: If provided, the class performs precomputations that
        only depend on the number of samples, e.g., computing the template
        signal.  If not provided, the class does not perform precomputations.
        Instead, it does the computations once the input signal was provided 
        and the class learns the number of samples from the input signal. 
        Setting samples_count is highly recommended.  If the feaure extraction
        method is being used in loop (e.g., BCI2000 loop), setting this 
        parameter eliminates the need to compute the template matrix each
        time. It also helps the class to avoid other computations in each
        iteration. samples_count passed to this function must be the same 
        as the third dimension size of the signal passed to extract_features().
        If that is not the case, the template and input signal will have 
        different dimensions.  The class should issue an error in this case
        and terminate the execution. 
        """
        self.build_feature_extractor(
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=subbands,           
            embedding_dimension=embedding_dimension,
            delay_step=delay_step,
            filter_order=filter_order,
            filter_cutoff_low=filter_cutoff_low,
            filter_cutoff_high=filter_cutoff_high,
            voters_count=voters_count,
            random_seed=random_seed,
            use_gpu=use_gpu,
            max_batch_size=max_batch_size,
            explicit_multithreading=explicit_multithreading,
            samples_count=samples_count)
        
        self.ar_order = ar_order
        self.energy_ratio = energy_ratio
            
    def get_features(self, device):
        """Extract MEC features (SNRs) from signal"""    
        # Extract current batch of data
        (signal, y_bar_squared) = self.get_current_data_batch()
                
        xp = self.get_array_module(signal)
        
        # Swap the dimensions for samples and electrodes to make the 
        # implementation consistent with the reference.
        signal = xp.transpose(signal, axes=(0, 2, 1))         
        
        # Extract SNRs                   
        features = self.compute_snr(signal, y_bar_squared, device)
               
        batch_size = self.channel_selection_info_bundle[1]
        
        # De-bundle the results.
        features = xp.reshape(features, (
            features.shape[0]//batch_size,
            batch_size,
            self.targets_count,
            self.features_count)
            )
        
        return features
    
    def get_features_multithreaded(self, signal):
        """Extract MEC features (SNRs) from signal"""        
        # signal is an E by T 2D array, where T is the number
        # of samples and E is the number of electrodes.  Thus, we must
        # transpose to make it T by E. 
        signal -= np.mean(signal, axis=-1)[:, None]
        signal /= np.std(signal, axis=-1)[:, None]
        signal = np.transpose(signal)
        signal = signal[None, :, :]
        
        # Compute Ybar per Eq. (9)
        y_bar = signal - np.matmul(self.xplus, signal)
        
        y_bar_squared = np.matmul(
            np.transpose(y_bar, axes=(0, 2, 1)), y_bar)
        
        y_bar_squared = y_bar_squared[None, :, :, :]                             
        features = self.compute_snr(signal, y_bar_squared, device=0)    

        # De-bundle the results.
        features = np.reshape(features, (
            1, 
            1,
            1,
            self.targets_count,
            1))        
        return features
       
    def compute_snr(self, signal, y_bar_squared, device):
        """Compute the SNR"""         
        xp = self.get_array_module(signal)
        
        # Project the signal to minimize the power of nuisance signal
        (projected_signal, n_s) = self.project_signal(
            signal, y_bar_squared, device)    
        
        # Computer the signal power
        template = self.template_signal_handle[device][None, :, :, :]
        template = xp.transpose(template, axes=(0, 1, 3, 2))
        power = xp.matmul(template, projected_signal)
        power = xp.square(power)
        
        # The following is a trick to add each row of the matrix to the row 
        # below it and save it in the top row. One row is for the sine and
        # the other is for the cosine.
        power = power + xp.roll(power, -1, axis=2)
        power = power[:, :, 0:-1:2]
        power = xp.transpose(power, axes=(2, 0, 1, 3))    

        x_inverse_signal = xp.matmul(
            self.sub_template_inverse_handle[device][:, None, :, :, :], 
            projected_signal[None, :, :, :, :])
        
        x = xp.reshape(
            self.template_signal_handle[device], 
            self.template_signal_handle[device].shape[0:-1] + (-1, 2))
        
        x = xp.transpose(x, (2, 0, 1, 3))
        s_bar = xp.matmul(x[:, None, : , :, :], x_inverse_signal)
        s_bar = projected_signal[None, :, :, :, :] -  s_bar
        s_bar = xp.transpose(s_bar, axes=(0, 1, 2, 4, 3))        
        
        # Extract the noise energy
        coefficients, noise_energy = self.yule_walker(s_bar, device)
        sigma_bar = self.k2 * noise_energy        
        denominator = xp.zeros(coefficients.shape[0:-1], dtype=np.cdouble)
        coefficients = xp.transpose(coefficients, axes=(3, 0, 1, 2, 4))
        coefficients *= -1
        
        coefficients = xp.multiply(
            coefficients, self.k3_handle[device][None, :, None, :, :])
        
        denominator = xp.sum(coefficients, axis=-1)
        denominator = xp.transpose(denominator, axes=(1, 2, 3, 0))
        denominator = xp.abs(1 + denominator)
        sigma_bar /= denominator
        power = power / sigma_bar
        
        # For each signal, only keep the first n_s number of channels.
        snrs = xp.sum(power, axis=0)
        snrs = xp.cumsum(snrs, axis=-1)    

        snrs_reshaped = xp.reshape(snrs, (-1, snrs.shape[2]))
        ns = 1 + xp.arange(snrs_reshaped.shape[-1])
        ns = xp.multiply(xp.ones(snrs_reshaped.shape), ns[None, :])
        ns = (ns == (n_s.flatten())[:, None])
        snrs_reshaped = snrs_reshaped[ns]
        snrs = xp.reshape(snrs_reshaped, snrs.shape[0:2])
        
        a = cp.asnumpy(snrs)
        if np.isnan(a).any():
            b = 3
        
        return snrs        
                            
    def project_signal(self, signal, y_bar_squared, device):
        """Project the signal such that noise has the minimum energy"""  
        xp = self.get_array_module(signal)
          
        # Compute eigen values and eigen vectors, which give us the
        # solution to the optimization problem of Eq. (10).
        # The matrix is symmetric, thus we use eigh function.
        eigen_values, eigen_vectors = xp.linalg.eigh(y_bar_squared)
        
        # Compute how many channes we need to keep based on the desired 
        # energy of the retained noise. See Eq. (12)
        n_s = self.compute_channels_count(eigen_values, device)
        
        # The following manipulations are simply to normalize eigen vectors
        eigen_values = xp.sqrt(eigen_values)
        eigen_values = xp.expand_dims(eigen_values, axis=3)       
        eigen_vectors = xp.transpose(eigen_vectors, axes=(0, 1, 3, 2))
        eigen_vectors = xp.divide(eigen_vectors, eigen_values)
        eigen_vectors = xp.transpose(eigen_vectors, axes=(0, 1, 3, 2))
        
        # It is possible that each signal in the batch needs a different
        # number of channels.  This prevents us from keeping everything in a 
        # single matrix to batch-process them.  To overcome this, we compute
        # the maximum number of channels in the batch and keep that many
        # channels.  Later on in the code, we will discard the remaining
        # channels that were supposed to be discarded here.  
        max_index = xp.max(n_s)
        eigen_vectors = eigen_vectors[:, :, :, 0:max_index]
        
        # Compute the projected signal per Eq. (7).
        projected_signal = xp.matmul(signal[:, None, :, :], eigen_vectors)            
        return (projected_signal, n_s)
    
    def compute_channels_count(self, eigen_values, device):
        """Compute how many channels we need based on ratio of energy."""        
        # The following is a pythonic implementation of Eq. (12)   
        xp = self.get_array_module(eigen_values)
        running_sum = xp.cumsum(eigen_values, axis=-1)
        total_energy = xp.expand_dims(running_sum[:, :, -1], axis=-1)
        energy_ratio = xp.divide(running_sum, total_energy)
        flags = (energy_ratio <= self.energy_ratio_handle[device])        
        n_s = xp.sum(flags, axis=-1)        
        n_s[n_s == 0] = 1
        return n_s
        
    def yule_walker(self, time_series, device):       
        "Yule-Walker AR model estimation, based on the sm models"            
        xp = self.get_array_module(time_series)
        
        # A short hand for ar_order
        p = self.ar_order

        if self.use_gpu == True: 
            batch_size = 5
            
            # The custom kernel works with 3D arrays only.
            shape = time_series.shape
            time_series = xp.reshape(time_series, (-1, shape[-1]))
            
            # One is added in case the samples count is not divisible by batch_size
            # Adding extra zeros does not affect the summation, so it is safe.
            batch_count = shape[-1]//batch_size + 1
                         
            # Helps us keep track of indexing time_series in the kernel 
            # considering that the sizes of time_series and r do not mach any more
            # (because of the +1 we have in the previous statement)
            offset = batch_count * batch_size - shape[-1]
            
            r = xp.zeros(
                (p+1,) + shape[0:-1] + (batch_count,), dtype=xp.float32) 
            
            r = xp.reshape(r, (p+1, -1, batch_count))    
            
            # Kernel settings
            grid_size = (r.shape[1], r.shape[0])        
            block_size = (batch_count,)
                       
            self.sum_product_raw(grid_size, block_size, (
                time_series, batch_size, shape[-1],
                time_series.size, offset, r))
            
            r = xp.sum(r, axis=-1)
            r = xp.reshape(r, (p+1,) + shape[:-1])   
            
        else:            
            r = xp.zeros((p+1,) + time_series.shape[0:-1], dtype=xp.float32)                
            r[0] = xp.sum(xp.square(time_series), axis=-1)
        
            # By far, the slowest part of the entire algorithm.        
            for k in xp.arange(1, p+1): 
                r[k] = xp.sum(xp.multiply(
                    time_series[:, :, :, :, :-k], 
                    time_series[:, :, :, :,  k:]),
                    axis=-1) 
           
        r = xp.transpose(r, axes=(1, 2, 3, 4, 0))
        r = r / self.samples_count_handle[device]   
        G = xp.zeros(r.shape[:-1] + (p, p), dtype=xp.float32) 
        G[:, :, :, :, 0, :] = r[:, :, :, :, :-1]
        
        for i in np.arange(1, p):
            G[:, :, :, :, i, i:] = r[:, :, :, :, :-i-1]
          
        # Construct a toeplitz matrix.
        # Such matrix can be constructed using the following transformation:
        # (1/a0)A = GGT - (G - I)(G - I)T = G + GT - I
        A = xp.divide(G, (G[:, :, :, :, 0, 0])[:, :, :, :, None, None])
        A = A + xp.transpose(A, axes=(0, 1, 2, 3, 5, 4))
        A = xp.subtract(A, xp.eye(A.shape[-1], dtype=xp.float32))
        R = xp.multiply(A, (G[:, :, :, :, 0, 0])[:, :, :, :, None, None])
        rho = xp.linalg.solve(R, r[:, :, :, :, 1:])
        sigmasq = xp.sum(xp.multiply(r[:, :, :, :, 1:], rho), axis=-1)
        sigmasq =  r[:, :, :, :, 0] - sigmasq     
        
        # Returns the coefficients and noise energy
        return rho, sigmasq
    
    def perform_voting_initialization(self, device):
        """Perform initialization and precomputations common to all voters"""              
        # Normalize all data
        self.all_signals -= np.mean(self.all_signals, axis=-1)[:, :, None]
        self.all_signals /= np.std(self.all_signals, axis=-1)[:, :, None]    
        
        # Generate handles to normalized data
        self.all_signals_handle = self.handle_generator(self.all_signals)
        
        # The rest is only needed for gpu-based and single-threaded only!
        if self.explicit_multithreading > 0:
            return
        
        signal = self.all_signals_handle[device]      
        xp = self.get_array_module(signal)

        # Pre-compute y_bar per Eq. (9).
        signal = xp.transpose(signal, axes=(0, 2, 1))
        
        # An artifical for loop is ensuing!
        # Although it could be avoided, using a for loop eases up memory usage.
        y_bar = xp.zeros(
            (self.signals_count,
              self.targets_count,
              self.samples_count,
              self.electrodes_count), dtype=xp.float32)
        
        for i in xp.arange(self.signals_count):
            y_bar[i] = xp.matmul(
                self.xplus_handle[device],
                signal[i, :, :])    
        
        # Equivalent to the For loop above but needs more memory to compute
        # everything in one shot. 
        # y_bar = xp.matmul(
        #     self.xplus_handle[device][None, :, :, :],
        #     signal[:, None, :, :])           
        
        y_bar = xp.subtract(signal[:, None, :, :], y_bar)
                  
        self.y_bar_squared = xp.matmul(
            xp.transpose(y_bar, axes=(0, 1, 3, 2)), y_bar)  
        
        # Generate handles
        self.y_bar_squared_handles = self.handle_generator(self.y_bar_squared)
        
    def class_specific_initializations(self):
        """Perform necessary initializations and precomputations"""
        # Perform some percomputations only in the first run.  
        # These computations only rely on the template signal and can thus
        # be pre-computed to improve performance. 
        self.compute_templates()  
        
        # Get the inverse of sine and cosine pairs of each harmonic. 
        # Need for computing SNR later on. 
        self.precompute_each_harmonic_inverse()
        
        self.xplus = np.matmul(
            self.template_signal,
            np.linalg.pinv(self.template_signal))
                
        # Compute some constants. We need them later for computing SNR. 
        k1 = ((-2 * 1j * np.pi / self.sampling_frequency)
              * self.targets_frequencies)
        k1 = np.multiply(
            k1[:, None], (np.arange(1, self.ar_order+1)[:, None]).T)
        k2 = np.pi * self.samples_count / 4
        harmonics_scaler = np.arange(1, self.harmonics_count+1)
        k3 = np.multiply(harmonics_scaler[:, None, None], k1)
        k3 = np.exp(k3)        
        self.k3 = k3
        self.k2 = k2
        
        # Create handles
        self.template_signal_handle = self.handle_generator(
            self.template_signal) 
        
        self.sub_template_inverse_handle = self.handle_generator(
            self.sub_template_inverse)
        
        self.xplus_handle = self.handle_generator(self.xplus)
        self.k2_handle = self.handle_generator(self.k2)
        self.k3_handle = self.handle_generator(self.k3)
        self.energy_ratio_handle = self.handle_generator(self.energy_ratio)           
        self.samples_count_handle = self.handle_generator(self.samples_count)
        
        # Force compile the kernel by running some dummy analysis. 
        if self.use_gpu == True:
            dummy = np.random.rand(8, 300)
            dummy = cp.asarray(dummy)
            r = cp.zeros((8, 8))
            self.sum_product_raw(
                (8, 8), (64,), (dummy, 10, 300, dummy.size, 0, r)
                )
                   
    def precompute_each_harmonic_inverse(self):
        """"pre-compute the iverse of each harmonics."""        
        # This saves up like 5% performance.
        # Extract sine and cosine pair of each harmonic and compute its
        # inverse.  This is needed for computing the SNRs.  It needs to be done
        # only once. 
        self.sub_template_inverse = np.zeros(
            (self.harmonics_count,
              self.template_signal.shape[0],
              2,
              self.template_signal.shape[1]))
        
        for h in np.arange(0, self.harmonics_count*2, 2):
            x = self.template_signal[:, :, (h, h+1)]
            self.sub_template_inverse[np.int32(h/2)] = np.linalg.pinv(x)
            
    def get_current_data_batch(self):
        """Bundle all data so they can be processed toegher"""
        # Bundling helps increase GPU and CPU utilization. 
       
        # Extract bundle information. 
        # Helps with the code's readability. 
        batch_index = self.channel_selection_info_bundle[0]        
        batch_population = self.channel_selection_info_bundle[1]
        batch_electrodes_count = self.channel_selection_info_bundle[2]
        first_signal = self.channel_selection_info_bundle[3]
        last_signal = self.channel_selection_info_bundle[4]
        signals_count = last_signal - first_signal
        
        # Pre-allocate memory for the batch
        signal = np.zeros(
            (signals_count, batch_population,
             batch_electrodes_count, self.samples_count),
            dtype=np.float32)        
                
        y_bar_squared = np.zeros(
            (signals_count, batch_population, self.targets_count, 
             batch_electrodes_count, batch_electrodes_count),
            dtype=np.float32)
        
        selected_signals = self.all_signals_handle[0][first_signal:last_signal]  
        selected_ybar = self.y_bar_squared_handles[0][first_signal:last_signal]
    
        for j in np.arange(batch_population):
            current_selection = self.channel_selections[batch_index]
            signal[:, j] = selected_signals[:, current_selection, :]     
            ybar2 = selected_ybar[:, :, current_selection, :]
            ybar2 = ybar2[:, :, :, current_selection]     
            y_bar_squared[:, j] = ybar2
            batch_index += 1
            
        signal = np.reshape(signal, (-1,) + signal.shape[2:])
        
        y_bar_squared = np.reshape(
            y_bar_squared, (-1,) + y_bar_squared.shape[2:])
          
        # Move the extracted batches to the device memory if need be. 
        if self.use_gpu == True:      
            signal = cp.asarray(signal)
            y_bar_squared = cp.asarray(y_bar_squared)
            
        return (signal, y_bar_squared)
                      
    @property
    def ar_order(self):
        """Getter function for the order of the autoregressive model"""
        return self.__ar_order
    
    @ar_order.setter
    def ar_order(self, order):
        """Setter function for the order of the autoregressive model"""
        error_message = "Oorder of the AR model must be a positive integer."
        
        try:
            order = int(order)
        except (ValueError, TypeError):
            self.quit(error_message)
            
        if order <= 0:
            self.quit(error_message)     
            
        self.__ar_order = order
        
    @property
    def energy_ratio(self):
        """Getter function for energy ratio"""
        return self.__energy_ratio
    
    @energy_ratio.setter
    def energy_ratio(self, energy_ratio):
        """Setter function for energy ratio"""
        error_message = "Energy ratio must be a real number between 0 and 1"
        
        try:
            energy_ratio = float(energy_ratio)
        except (ValueError, TypeError):
            self.quit(error_message)
            
        if not 0 < energy_ratio < 1:
            self.quit(error_message)    
            
        self.__energy_ratio = energy_ratio

```

``` ./__init__.py
from .featureExtractor import FeatureExtractor
from .featureExtractorTemplateMatching import FeatureExtractorTemplateMatching
from .featureExtractorCCA import FeatureExtractorCCA
from .featureExtractorMEC import FeatureExtractorMEC
from .featureExtractorMSI import FeatureExtractorMSI

```

``` ./featureExtractorMSI.py
# featureExtractorMSI.py
"""
Implementation of MSI feature extractor.
Zhang, Yangsong, et al. "The extension of multivariate 
synchronization index method for SSVEP-based BCI." Neurocomputing
269 (2017): 226-231
"""
# Import the definition of the parent class.  Make sure the file is in the
# working directory. 
from .featureExtractorTemplateMatching \
    import FeatureExtractorTemplateMatching

# Needed for many matrix computations.
import numpy as np

try:
    import cupy as cp
    cupy_available_global = True
except:
    cupy_available_global = False
    cp = np

class FeatureExtractorMSI(FeatureExtractorTemplateMatching):
    """Class of MSI feature extractor"""
    
    def __init__(self):        
         """MSI feature extractor class constructor"""         
         super().__init__()
                 
         # This is the covariance matrix of the template SSVEP. 
         # We can pre-compute this once to improve performance.
         self.C22 = 0
         
    def setup_feature_extractor(
            self, 
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            embedding_dimension=0,
            delay_step=0,
            filter_order=0,
            filter_cutoff_low=0,
            filter_cutoff_high=0,
            subbands=None,
            voters_count=1,
            random_seed=0,
            use_gpu=False,
            max_batch_size=16,
            explicit_multithreading=0,
            samples_count=0):
        """
        Setup the feature extractor parameters (MSI).
        
        Mandatory Parameters:
        ---------------------
        harmonics_count: The number of harmonics to be used in constructing
        the template signal.  This variable must be a positive integer 
        number (typically a value from 3 to 5).  
        
        targets_frequencies: The stimulation freqeuency of each target.  
        This must be a 1D array,  where the first element is the stimulation
        frequency of the first target, the second element is the stimulation
        frequency of the second target, and so on.  The length of this array
        indicates the number of targets.  The user must determine the 
        targets_frequencies but the number of targets (targets_count) is 
        extracted automatically from the length of targets_frequencies. 
        
        sampling_frequency: The sampling rate of the signal 
        (in samples per second).  It must be a real positive value.
        
        Optional Parameters:
        --------------------        
        embedding_dimension: This is the dimension of time-delay embedding. 
        This must be a non-negative integer.  If set to zero, no time-dely
        embedding will be used.  If there are E electrodes and we set the 
        embedding_dimension to n, the class expands the input signal as if we
        had n*E channels.  The additional channels are generated by shift_left
        operator. The number of samples that we shift each signal is 
        controlled by delay_step.  Embedding delays truncates the signal. 
        Make sure the signal is long enough. 
        
        delay_step: The number of samples that are shifted for each delay
        embedding dimension.  For example, assume we have ten channels, 
        embedding_dimension is two, and delay_step is three.  In this case, the
        class creates 30 channels.  The first ten channels are the original
        signals coming from the ten electrodes.  The second ten signals are
        obtained by shifting the origianl signals by three samples.  The third
        ten signals are obtained by shifting the original signals by six 
        samples.  The signals are truncated accordingly. 
        
        filter_order: The order of the filter used for filtering signals before
        analysis.  If filter_order is zero (the default value), no filtering
        is performed.  Otherwise, the class creates a filter of order 
        filter_order.  This must be positive integer. 
        
        cutoff_frequency_low: The first cutoff frequency of the bandpass 
        filter.  This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        cutoff_frequency_high: The second cutoff frequency of the bandpass
        filter. This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        subbands: This is the primary way to instruct the classifier whether 
        to use filterbank or not.  The default value is None.  If set to None, 
        the classifier uses none-fitlerbank implementation.  To use
        filterbanks, subbands must be set to a 2D array, whith exactly two 
        columns.  Each row of this matrix defines a subband with two 
        frequencies provided in two columns.  The first column is the first
        cutoff frequency and the second column is the second cutoff frequency
        of that subband.  Filterbank filters the signal using a bandpass
        filter with these cutoff frequencies to obtain a new subband.  The
        number of rows in the matrix defines the number of subbands. All
        frequencies must be in Hz.  For each row, the second column must
        always be greater than the first column. 
        
        voters_count: The number of electrode-selections that are used for
        classification.  This must be a positive integer.  This is the 
        same as the number of voters.  If voters_count is larger that the 
        cardinality of the power set of the current selected electrodes, 
        then at least one combination is bound to happen more than once. 
        However, because the selection is random, even if voters_count is
        less than the cardinality of the power set, repettitions are still
        possible (although unlikely). If not specified or 1, no 
        voting will be used. 
        
        random_seed: This parameter control the seed for random selection 
        of electrodes.  This must be set to a non-negative integer.  The 
        default value is zero.
                
        use_gpu: When set to 'True,' the class uses a gpu to extract features.
        The host must be equipped with a CUDA-capable GPU.  When set to
        'False,' all processing will be on CPU. 
        
        max_batch_size: The maximum number of signals/channel selections
        that are processed in one batch.  Increasing this number improves
        parallelization at the expense of more memory requirement.  
        This must be a single positve integer. 
        
        explicit_multithreading: This parameter determines whether to use 
        explicit multithreading or not.  If set to a non-positive integer, 
        no multithreading will be used.  If set to a positive integer, the 
        class creates multiple threads to process signals/voters in paralle.
        The number of threads is the same as the value of this variable. 
        E.g., if set to 4, the class distributes the workload among four 
        threads.  Typically, this parameter should be the same as the number
        of cores the cput has, if multithreading is to be used. 
        Multithreading cannot be used when use_gpu is set to True.
        If multithreading is set to a positive value while used_gpu is 
        set to True or vice versa, the classes raises an error and the 
        program terminates. 
        
        samples_count: If provided, the class performs precomputations that
        only depend on the number of samples, e.g., computing the template
        signal.  If not provided, the class does not perform precomputations.
        Instead, it does the computations once the input signal was provided 
        and the class learns the number of samples from the input signal. 
        Setting samples_count is highly recommended.  If the feaure extraction
        method is being used in loop (e.g., BCI2000 loop), setting this 
        parameter eliminates the need to compute the template matrix each
        time. It also helps the class to avoid other computations in each
        iteration. samples_count passed to this function must be the same 
        as the third dimension size of the signal passed to extract_features().
        If that is not the case, the template and input signal will have 
        different dimensions.  The class should issue an error in this case
        and terminate the execution. 
        """
        self.build_feature_extractor(
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=subbands,           
            embedding_dimension=embedding_dimension,
            delay_step=delay_step,
            filter_order=filter_order,
            filter_cutoff_low=filter_cutoff_low,
            filter_cutoff_high=filter_cutoff_high,
            voters_count=voters_count,
            random_seed=random_seed,
            use_gpu=use_gpu,
            max_batch_size=max_batch_size,
            explicit_multithreading=explicit_multithreading,
            samples_count=samples_count)
                        
    def get_features(self, device):
        """Extract MSI features (synchronization indexes) from signal"""                          
        signal = self.get_current_data_batch()        
        xp = self.get_array_module(signal)
        
        features = self.compute_synchronization_index(signal, device)
        batch_size = self.channel_selection_info_bundle[1]
        
        features = xp.reshape(features, (
            features.shape[0]//batch_size,
            batch_size,
            self.targets_count,
            self.features_count)
            )
        return features
    
    def get_features_multithreaded(self, signal):
        """Extract MSI features from a single signal"""        
        # Make sure signal is 3D
        signal -= np.mean(signal, axis=-1)[:, None]
        signal = signal[None, :, :] 
        features = self.compute_synchronization_index(signal, device=0)  

        # De-bundle the results.
        features = np.reshape(features, (
            1, 
            1,
            1,
            self.targets_count,
            self.features_count)
            )
          
        return features
    
    def compute_synchronization_index(self, signal, device):
        """Compute the synchronization index between signal and templates"""        
        xp = self.get_array_module(signal)        
        electrodes_count = signal.shape[1]        
        r_matrix = self.compute_r(signal, device)        
        
        # Keep only the first output of the function
        eigen_values = xp.linalg.eigh(r_matrix)[0]
        eigen_values = (eigen_values / (
            2*self.harmonics_count_handle[device]+electrodes_count)
            )

        score = xp.multiply(eigen_values, xp.log(eigen_values))
        score = xp.sum(score, axis=-1)
        score = score / xp.log(r_matrix.shape[-1])
        score += 1
        return score
      
    def compute_r(self, signal, device):
        """Compute matrix C as explained in Eq. (7)"""
        xp = self.get_array_module(signal)
        C11 = self.get_data_covariance(signal, device)
        
        C11 = xp.expand_dims(C11, axis=1)
        signal = xp.expand_dims(signal, axis=1)
        
        C12 = xp.matmul(
            signal, (self.template_signal_handle[device])[None, :, :, :])
                       
        C12 = C12 / self.samples_count_handle[device]
        electrodes_count = C11.shape[-1]
        
        # Eq. (6)
        upper_left = xp.matmul(C11, C12)
        upper_left = xp.matmul(upper_left, self.C22_handle[device])
        
        lower_right = xp.matmul(
            self.C22_handle[device], xp.transpose(C12, axes=[0, 1, 3, 2]))
        
        lower_right = xp.matmul(lower_right, C11)        
        eye1 = xp.eye(electrodes_count, dtype=xp.float32)   
        
        eye1 = eye1 + xp.zeros(
            upper_left.shape[0:2] + eye1.shape, dtype=xp.float32)
        
        eye2 = xp.eye(C12.shape[-1], dtype=xp.float32)
        
        eye2 = eye2 + xp.zeros(
            upper_left.shape[0:2] + eye2.shape, dtype=xp.float32)
        
        part1 = xp.concatenate((eye1, upper_left), axis=-1)
        part2 = xp.concatenate((lower_right, eye2), axis=-1)
        r_matrix = xp.concatenate((part1, part2), axis=-2)
       
        return xp.real(r_matrix)
                
    def get_data_covariance(self, signal, device):
        """Compute the covariance of data per Eq. (3) and Eq. (6)"""
        xp = self.get_array_module(signal)
        C11 = xp.matmul(signal, xp.transpose(signal, axes=(0, 2, 1)))
        C11 = C11 / self.samples_count_handle[device]
        C11 = xp.linalg.inv(C11)
        C11 = self.matrix_square_root(C11)
        return C11
    
    def matrix_square_root(self, A):
        """Compute the square root of a matrix using ev decomposition"""
        xp = self.get_array_module(A)
        w, v = xp.linalg.eigh(A)
        D = xp.zeros(A.shape, dtype=xp.float32)        
        w = xp.sqrt(w)
        
        for i in xp.arange(w.shape[-1]):
            D[:, i, i] = w[:, i]
            
        sqrt_A = xp.matmul(xp.matmul(v, D), xp.linalg.inv(v))
        return sqrt_A
            
    def perform_voting_initialization(self, device=0):
        """Perform initialization and precomputations common to all voters"""
        # Center data
        self.all_signals -= np.mean(self.all_signals, axis=-1)[:, :, None]        
        self.all_signals_handle = self.handle_generator(self.all_signals)
                   
    def class_specific_initializations(self):
        """Perform necessary initializations"""
        # Perform some percomputations only in the first run.  
        # These computations only rely on the template signal and can thus
        # be pre-computed to improve performance. 
        self.compute_templates()  
        self.precompute_template_covariance()
        
        # Create handles
        # Handles make it easier to expand the algorithm to work with
        # multiple CPUs or GPUs
        self.template_signal_handle = self.handle_generator(
            self.template_signal) 
        self.C22_handle = self.handle_generator(self.C22)
        
        self.harmonics_count_handle = self.handle_generator(
            self.harmonics_count)
        
        # It is important to cast these to float32.
        # Otherwise, cupy casts the results back to float64 when dividing
        # float32 by int32.
        self.samples_count_handle = self.handle_generator(
            np.float32(self.samples_count))
        
    def precompute_template_covariance(self):
        """Pre-compute and save the covariance matrix of the template"""
        # Eq. (4)
        C22 = np.matmul(            
            np.transpose(self.template_signal, axes=[0, 2, 1]),
            self.template_signal)
        
        C22 = C22 / self.samples_count
        
        # Eq. (6)
        C22 = np.linalg.inv(C22)            
        self.C22 = self.matrix_square_root(C22)      
               
    def get_current_data_batch(self):
        """Bundle all data so they can be processed toegher"""
        # Bundling helps increase GPU and CPU utilization. 
       
        # Extract bundle information. 
        # Helps with the code's readability. 
        batch_index = self.channel_selection_info_bundle[0]        
        batch_population = self.channel_selection_info_bundle[1]
        batch_electrodes_count = self.channel_selection_info_bundle[2]
        first_signal = self.channel_selection_info_bundle[3]
        last_signal = self.channel_selection_info_bundle[4]
        signals_count = last_signal - first_signal
        
        # Pre-allocate memory for the batch
        signal = np.zeros(
            (signals_count, batch_population,
             batch_electrodes_count, self.samples_count),
            dtype=np.float32)        
        
        selected_signals = self.all_signals_handle[0][first_signal:last_signal]
        
        for j in np.arange(batch_population):
            current_selection = self.channel_selections[batch_index]
            signal[:, j] = selected_signals[:, current_selection, :]
            batch_index += 1
                        
        signal = np.reshape(signal, (-1,) + signal.shape[2:])
          
        # Move the extracted batches to the device memory if need be. 
        if self.use_gpu == True:          
            signal = cp.asarray(signal)
            
        return signal
```

``` ./featureExtractorTemplateMatching.py
# featureExtractorTemplateMatching.py
"""Definition for the parent class for CCA, MEC, and MSI"""
from .featureExtractor import FeatureExtractor
import numpy as np

class FeatureExtractorTemplateMatching(FeatureExtractor):
    """A parent class for CCA, MEC, and MSI"""
    
    __targets_frequencies_setup_guide = (
        "The frequencies of targets must be a one dimensional array of real "
        + "positive numbers, where the first element represents the "
        + "frequency of the first target, the second element is the "
        + "frequency of the scond target, and so on. All frequencies must "
        + "be in Hz. ")
    
    def __init__(self):
        """Setting all attributes to valid initiali values"""
        super().__init__()
        
        # Hold the pre-computed template signals for SSVE.
        # This is a 3D array, with dimensions of [number of targets, 2*Nh, 
        # number of samples].  Each target has a unique template signal that 
        # consistes of a linear combination of 2*Nh sinusoidal signals, where. 
        # Nh is the number of harmonics.  For each harmonic a (sine, cosine)
        # pair is computed, hence the midle dimension has the size of 2*Nh.
        self.template_signal = None
        
        # The number of harmonics or Nh as explained in the previous comment.
        # This must be a natural number (generally less than 5).  The user
        # must set this value.
        self.harmonics_count = 0
        
        # The stimulation freqeuency of each target.  This must be a 1D vector,
        # where the first element is the stimulation frequency of the first
        # target, the second element is the stimulation frequency of the 
        # second target, and so on.  The length of this vector indicates the
        # number of targets.  The user must determine the targets_frequencies
        # but the number of targets (targets_count) is extracted automatically
        # from the length of targets_frequencies. 
        self.targets_frequencies = None
        self.targets_count = 0
          
    def compute_templates(self):
        """Pre-compute the template signals for all target frequencies"""
        # Template must have the same length as the signal.
        t = np.arange(1, self.samples_count+1)
        
        # Dividing by the sampling frequency returns the actual
        # time in seconds.
        t = t/self.sampling_frequency
        
        # Pre-compute the template signal.  This generates a 4D array.  
        # Index the first dimension to access the target.  Index the 
        # second dimension to access harmonics.  Index the third dimension
        # to access either sine or cosine.  Index the fourth dimension to
        # access samples. 
        template_signal = np.array(
            [[(np.sin(2*np.pi*t*f*h), np.cos(2*np.pi*t*f*h))
             for h in range(1, self.harmonics_count+1)]
             for f in self.targets_frequencies])
        
        # Reshape template_signal into a 3D array, where the first dimension
        # indexes targets, the second dimension indexes harmonics and 
        # sine/cosine, and the third dimension indexes samples. 
        # The first enetry of the second dimension is the sine wave of the 
        # fundamental frequency, the second entry is the cosine wave of the 
        # fundamental frequency, the third entry is the sine wave of the first
        # harmonic, the fourth entry is the cosine wave of the first harmonic,
        # and so on. 
        self.template_signal = np.reshape(
            template_signal, 
            (self.targets_count,
             self.harmonics_count*2,
             self.samples_count))
        
        self.template_signal = np.transpose(
            self.template_signal, axes=(0, 2, 1))
        
    @property
    def  template_signal(self):
        """Getter function for the template signals"""
        return self._template_signal
    
    @template_signal.setter
    def template_signal(self, template_signal):
        """Setter function for the template signals"""
        error_message = "template_signal must be a 3D array of floats."
        
        if template_signal is None:
            self._template_signal = 0
            return 
        
        try:
            template_signal = template_signal.astype(np.float32)
        except (ValueError, TypeError, AttributeError):
            self.quit(error_message)
        
        if not template_signal.ndim == 3:
            self.quit(error_message)
        
        self._template_signal = template_signal            
    
    @property
    def harmonics_count(self):
        """Getter function for the number of harmonics"""
        if self._harmonics_count == 0:
            self.quit("The number of harmonics is not set properly. "
                      + "To set the number of harmonics use the "
                      + "harmonics_count option of method "
                      + "setup_feature_extractor. ")
            
        return self._harmonics_count
    
    @harmonics_count.setter
    def harmonics_count(self, harmonics_count):
        """Setter method for the number of harmonics"""
        error_message = "Number of harmonics must be a positive integer."
        
        try:
            harmonics_count = int(harmonics_count)
        except (ValueError, TypeError):
            self.quit(error_message)
        
        if harmonics_count < 0:
            self.quit(error_message)      
          
        self._harmonics_count = harmonics_count 
        
    @property 
    def targets_frequencies(self):
        """Getter function for the frequencies of stimuli"""
        if self._targets_frequencies is None:
            self.quit("The frequencies of targets is not specified. To set "
                      + "this variable, use the targets_frequencies option "
                      + "of setup_feature_extractor. " 
                      + self.__targets_frequencies_setup_guide)
            
        return self._targets_frequencies
    
    @targets_frequencies.setter
    def targets_frequencies(self, stimulation_frequencies):
        """Setter function for the frequencies of stimuli"""
        error_message = ("Target frequencies must be an array of positive "
                         + "real numbers. ")
        error_message += self.__targets_frequencies_setup_guide
        
        if stimulation_frequencies is None:
            self._targets_frequencies = None
            self.targets_count = 0
            return
            
        try:
            stimulation_frequencies = np.array(stimulation_frequencies)
            stimulation_frequencies.astype(np.float32)
        except (ValueError, TypeError, AttributeError):
            self.quit(error_message)
            
        if stimulation_frequencies.ndim == 0:
            stimulation_frequencies = np.array([stimulation_frequencies])
        
        if np.array([stimulation_frequencies <= 0]).any():
           self.quit(error_message)
           
        self._targets_frequencies = stimulation_frequencies
        self.targets_count = stimulation_frequencies.size
        
    @property
    def targets_count(self):
        """Getter function for the number of targets"""
        if self._targets_count == 0:
            self.quit("The number of targets is not set. This happens "
                      + "because the target frequencies is not specified. "
                      + "To specify the target frequencies use the "
                      + "targets_frequencies option of the method "
                      + "setup_feature_extractor. ")
        return self._targets_count
    
    @targets_count.setter
    def targets_count(self, targets_count):
        """Setter function for the number of targets"""
        error_message = "Number of targets must be a positive integer."
        
        try:
            targets_count = int(targets_count)
        except (ValueError, TypeError):
            self.quit(error_message)
            
        if targets_count < 0:
            self.quit(error_message)
            
        self._targets_count = targets_count
```

