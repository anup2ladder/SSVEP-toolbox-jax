{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# MOABB Classifier comparison\n",
    "\n",
    "This notebook takes multiple files and does the following pipeline:\n",
    "1) Import data and pre-process\n",
    "2) For each stimulus type \n",
    "    1) Run classifiers (i.e., CCA, MEC, MSI, and RG)\n",
    "    2) Store accuracy values\n",
    "\n",
    "A final plot for each stimulus type is plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default libraries\n",
    "import re\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "from moabb.datasets import Wang2016, SSVEPExo\n",
    "from moabb.paradigms import FilterBankSSVEP, SSVEP\n",
    "from moabb.pipelines import ExtendedSSVEPSignal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from moabb.evaluations import CrossSubjectEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3\n"
     ]
    }
   ],
   "source": [
    "# Import custom libraries\n",
    "from ncantest import data_tools\n",
    "from ncantest import processing\n",
    "from ncantest import classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from FeatureExtractorSSVEP import FeatureExtractorCCA as CCA\n",
    "from FeatureExtractorSSVEP import FeatureExtractorMSI as MSI\n",
    "from FeatureExtractorSSVEP import FeatureExtractorMEC as MEC\n",
    "\n",
    "# Magic command to reload libraries\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Note that if the `Wang2016` is not already downloaded, it'll be downloaded the first time you run this section of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_config(\"MNE_DATA\", \"~/.mne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/.mne'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.get_config(\"MNE_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and epoch data\n",
    "dataset = Wang2016()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 2 subjects to speed up during testing\n",
    "dataset.subject_list = dataset.subject_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n",
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n"
     ]
    }
   ],
   "source": [
    "data = dataset.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_channels = [\"O1\",\"Oz\",\"O2\"]\n",
    "\n",
    "# Information from dataset description\n",
    "nsubjects = len(data)\n",
    "# labels_dict = {\"13\":0, \"17\":2, \"21\":1}  # The order is changed because the labels in the dataset are incorrect\n",
    "# stimulus_freqs = [int(f) for f in labels_dict.keys()]\n",
    "\n",
    "stimulus_freqs = [float(freq) for freq in dataset.event_id.keys()]  # Stimulus frequencies [Hz]\n",
    "srate = data[1][\"0\"][\"0\"].info['sfreq'] # Sampling rate [Hz]\n",
    "tmin = 0.5  # Time of start of SSVEP stimulus [sec]\n",
    "tmax = 5.5  # Time of end of SSVEP stimulus [sec]\n",
    "\n",
    "# Classifier settings\n",
    "# - Create CCA subbands like in Chen et al. (2015) paper\n",
    "first_column = np.arange(1, 11) * 8\n",
    "second_column = np.full(10, 88)\n",
    "cca_subbands = np.column_stack((first_column, second_column))\n",
    "harmonic_count = 2\n",
    "classifiers = [\"fbCCA\", \"MSI\", \"MEC\", \"RG_logreg\"]\n",
    "\n",
    "# Create an empty dataframe to store the accuracies\n",
    "accuracy_df = pd.DataFrame(\n",
    "    index = np.arange(0, nsubjects),\n",
    "    columns = classifiers\n",
    "    )\n",
    "accuracy_df.index.name = \"Subject\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Separate epochs\n",
    "\n",
    "From the raw recording datasets, create the EEG epochs using just the periods where the SSVEP stimulus was active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preallocate data\n",
    "epochs_list = [None] * len(data)\n",
    "events_list = [None] * len(data)\n",
    "\n",
    "# Obtain epochs and events\n",
    "for s, subject in data.items():\n",
    "    [events_list[s-1], epochs_list[s-1]] = data_tools.moabb_events_to_np(\n",
    "        mne_raw = subject[\"0\"][\"0\"],\n",
    "        tmin = tmin,\n",
    "        tmax = tmax,\n",
    "        events_dict = dataset.event_id,\n",
    "        chans = eeg_channels\n",
    "        )\n",
    "    \n",
    "# Convert lists to np.ndarrays\n",
    "# eeg_channels = data[1][\"0\"][\"0\"].ch_names\n",
    "epochs_np = np.float32(np.array(epochs_list))\n",
    "events_np = np.array(events_list[0][:,2]) - 1   # The `-1` is to make the labels start at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fbCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Platform 'METAL' is experimental and not all JAX functionality may be correctly supported!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1732580239.204691 2810203 mps_client.cc:510] WARNING: JAX Apple GPU support is experimental and not all JAX functionality is correctly supported!\n",
      "I0000 00:00:1732580239.212537 2810203 service.cc:145] XLA service 0x600003cf1400 initialized for platform METAL (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732580239.212548 2810203 service.cc:153]   StreamExecutor device (0): Metal, <undefined>\n",
      "I0000 00:00:1732580239.213705 2810203 mps_client.cc:406] Using Simple allocator.\n",
      "I0000 00:00:1732580239.213713 2810203 mps_client.cc:384] XLA backend will use up to 77309018112 bytes on device 0 for SimpleAllocator.\n"
     ]
    }
   ],
   "source": [
    "# Prototype and preallocate data\n",
    "cca = CCA()\n",
    "cca_accuracies = np.zeros(nsubjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: /Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:211:0: error: failed to legalize operation 'mhlo.custom_call'\n/Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractor.py:119:0: note: called from\n/Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:54:0: note: called from\n/var/folders/5b/t618zsqn799bvw97t8qmvj900000gn/T/ipykernel_35890/857691782.py:1:0: note: called from\n/Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:211:0: note: see current operation: %4:2 = \"mhlo.custom_call\"(%arg0) {backend_config = \"\", call_target_name = \"Qr\"} : (tensor<1251x4xf32>) -> (tensor<1251x4xf32>, tensor<4xf32>)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mharmonics_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mharmonic_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets_frequencies\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstimulus_freqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampling_frequency\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubbands\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcca_subbands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:54\u001b[0m, in \u001b[0;36mFeatureExtractorCCA.setup_feature_extractor\u001b[0;34m(self, harmonics_count, targets_frequencies, sampling_frequency, subbands, max_correlation_only, embedding_dimension, delay_step, filter_order, filter_cutoff_low, filter_cutoff_high, voters_count, random_seed, use_gpu, max_batch_size, samples_count)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_feature_extractor\u001b[39m(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     33\u001b[0m         harmonics_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;66;03m# explicit_multithreading=0,\u001b[39;00m\n\u001b[1;32m     48\u001b[0m         samples_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    Setup the feature extractor parameters CCA.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    [Same docstring as before...]\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mharmonics_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtargets_frequencies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubbands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubbands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_dimension\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelay_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_cutoff_low\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_cutoff_low\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_cutoff_high\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_cutoff_high\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvoters_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvoters_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# explicit_multithreading=explicit_multithreading,\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43msamples_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_correlation_only \u001b[38;5;241m=\u001b[39m max_correlation_only\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractor.py:119\u001b[0m, in \u001b[0;36mFeatureExtractor.build_feature_extractor\u001b[0;34m(self, harmonics_count, targets_frequencies, sampling_frequency, subbands, embedding_dimension, delay_step, filter_order, filter_cutoff_low, filter_cutoff_high, voters_count, random_seed, use_gpu, max_batch_size, samples_count)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# If samples_count is provided,\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m samples_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_specific_initializations\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_initialization_is_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:211\u001b[0m, in \u001b[0;36mFeatureExtractorCCA.class_specific_initializations\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_template \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_signal\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets_count):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_template\u001b[38;5;241m.\u001b[39mat[i]\u001b[38;5;241m.\u001b[39mset(\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_signal\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    213\u001b[0m rank_template \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mmatrix_rank(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_signal)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39many(rank_template \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mharmonics_count):\n",
      "    \u001b[0;31m[... skipping hidden 15 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/ssvep-jax/lib/python3.10/site-packages/jax/_src/compiler.py:267\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, module, options, host_callbacks)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m    262\u001b[0m         built_c, compile_options\u001b[38;5;241m=\u001b[39moptions, host_callbacks\u001b[38;5;241m=\u001b[39mhost_callbacks\n\u001b[1;32m    263\u001b[0m     )\n\u001b[1;32m    264\u001b[0m   \u001b[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    265\u001b[0m   \u001b[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    266\u001b[0m   \u001b[38;5;66;03m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilt_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompile_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m xc\u001b[38;5;241m.\u001b[39mXlaRuntimeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    269\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m error_handler \u001b[38;5;129;01min\u001b[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: /Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:211:0: error: failed to legalize operation 'mhlo.custom_call'\n/Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractor.py:119:0: note: called from\n/Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:54:0: note: called from\n/var/folders/5b/t618zsqn799bvw97t8qmvj900000gn/T/ipykernel_35890/857691782.py:1:0: note: called from\n/Users/satori/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-jax/FeatureExtractorSSVEP/featureExtractorCCA.py:211:0: note: see current operation: %4:2 = \"mhlo.custom_call\"(%arg0) {backend_config = \"\", call_target_name = \"Qr\"} : (tensor<1251x4xf32>) -> (tensor<1251x4xf32>, tensor<4xf32>)\n"
     ]
    }
   ],
   "source": [
    "cca.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1],\n",
    "    filter_order = 12,\n",
    "    subbands = cca_subbands,\n",
    "    use_gpu=True\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for s, subject in enumerate(epochs_np):\n",
    "    print(s)\n",
    "    # print(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cca_features = cca.extract_features(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cca_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_features[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.squeeze(cca_features)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.max(a, axis=1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.argmax(b, axis=1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(cca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_features.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array = np.array(cca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.max(np.squeeze(numpy_array), axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.squeeze(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.max(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_predictions = np.max(np.squeeze(cca_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_accuracies[s] = accuracy_score(events_np, cca_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(cca_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    cca_features = cca.extract_features(subject)\n",
    "    cca_predictions = np.argmax(np.max(np.squeeze(cca_features), axis=1), axis=1)\n",
    "    cca_accuracies[s] = accuracy_score(events_np, cca_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "accuracy_df[\"fbCCA\"] = cca_accuracies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df[\"fbCCA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### MEC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Prototype and preallocate data\n",
    "mec = MEC()\n",
    "mec_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "mec.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1]\n",
    ")\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    mec_features = mec.extract_features(subject)\n",
    "    mec_predictions = np.argmax(np.squeeze(mec_features), axis=1)\n",
    "    mec_accuracies[s] = accuracy_score(events_np, mec_predictions)\n",
    "\n",
    "accuracy_df[\"MEC\"] = mec_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Prototype and preallocate data\n",
    "msi = MSI()\n",
    "msi_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "msi.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1]\n",
    ")\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    msi_features = msi.extract_features(subject)\n",
    "    msi_predictions = np.argmax(np.squeeze(msi_features), axis=1)\n",
    "    msi_accuracies[s] = accuracy_score(events_np, msi_predictions)\n",
    "\n",
    "accuracy_df[\"MSI\"] = msi_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riemmanian geometry + logistic regression\n",
    "**IGNORE – FROM MOABB**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigm_fb = FilterBankSSVEP(\n",
    "    filters = None,\n",
    "    n_classes = 10,\n",
    "    tmin = tmin,\n",
    "    tmax = tmax,\n",
    "    channels = eeg_channels,\n",
    ")\n",
    "\n",
    "# paradigm = SSVEP(\n",
    "#     fmin = 6,\n",
    "#     fmax = 90,\n",
    "#     n_classes = 5,\n",
    "#     tmin = tmin,\n",
    "#     tmax = tmax,\n",
    "# )\n",
    "\n",
    "pipeline_rg = {}\n",
    "pipeline_rg[\"RG+LogReg\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    ")\n",
    "\n",
    "evaluation_rg = CrossSubjectEvaluation(\n",
    "    paradigm = paradigm_fb,\n",
    "    datasets = dataset,\n",
    "    overwrite = False\n",
    ")\n",
    "\n",
    "accuracy_rg = evaluation_rg.process(pipeline_rg)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracy_df[\"RG_logreg\"] = accuracy_rg[\"score\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Testing code, might have to be removed\n",
    "# Preallocate data\n",
    "# rg_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "# # Classify all epochs per subject\n",
    "# for s, subject in enumerate(epochs_np):\n",
    "#     rg_predictions = classification.fb_rg_logreg(\n",
    "#         eeg_data = subject,\n",
    "#         stim_freqs = stimulus_freqs,\n",
    "#         eeg_channels = eeg_channels, \n",
    "#         srate = srate,\n",
    "#         labels = events_np,\n",
    "#         )\n",
    "    \n",
    "#     rg_accuracies[s] = accuracy_score(events_np, rg_predictions)\n",
    "\n",
    "# # Store accuracies in dataframe\n",
    "# accuracy_df['RG_logreg'] = rg_accuracies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Testing code, might have to be removed\n",
    "# rg_accuracies = np.zeros(nsubjects)\n",
    "# for [s, subject] in enumerate(epochs_np):\n",
    "#     rg_predictions = classification.rg_logreg(\n",
    "#         eeg_data = subject,\n",
    "#         labels = events_np,\n",
    "#         )\n",
    "    \n",
    "#     rg_accuracies[s] = accuracy_score(events_np, rg_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifiers = ['fbCCA', 'MSI', 'MEC', 'RG_logreg']\n",
    "\n",
    "# stimulus_accuracy = accuracy_df[accuracy_df[\"Stimulus\"]==stimulus]\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\n",
    "sns.stripplot(\n",
    "    data=accuracy_df,\n",
    "    ax=ax,\n",
    "    jitter=True,\n",
    "    alpha=0.5,\n",
    "    zorder=1,\n",
    "    palette=\"Set1\",\n",
    ")\n",
    "sns.pointplot(data=accuracy_df, ax=ax, palette=\"Set1\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "classifiers = [\"fbCCA\", \"MSI\", \"MEC\", \"RG_logreg\"]\n",
    "# accuracy_df[classifiers[0]] = accuracy_rg[\"score\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create a 2x2 subplot grid\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.boxplot(\n",
    "    data = accuracy_df[classifiers],\n",
    "    ax = ax,\n",
    "    color = \"black\",\n",
    "    boxprops=dict(facecolor='none'),\n",
    "    # fill = False,\n",
    "    width = 0.5,\n",
    "    linewidth = 1   \n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data = accuracy_df[classifiers],\n",
    "    ax = ax,\n",
    "    jitter = 0.15,\n",
    "    alpha = 0.9,\n",
    "    zorder = 1,\n",
    "    palette = \"Set1\",\n",
    ")\n",
    "\n",
    "ax.set_ylim(-0.05, 1.05) \n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "# ax.set_xlabel(\"Classifier\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "fig.savefig(\"figures\\\\moabb_boxplot_comparison.svg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_results = True\n",
    "\n",
    "if save_results:\n",
    "    accuracy_df.to_csv(\"results_ncan_moabb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
