{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# MOABB Classifier comparison\n",
    "\n",
    "This notebook takes multiple files and does the following pipeline:\n",
    "1) Import data and pre-process\n",
    "2) For each stimulus type \n",
    "    1) Run classifiers (i.e., CCA, MEC, MSI, and RG)\n",
    "    2) Store accuracy values\n",
    "\n",
    "A final plot for each stimulus type is plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default libraries\n",
    "import re\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "from moabb.datasets import Wang2016, SSVEPExo\n",
    "from moabb.paradigms import FilterBankSSVEP, SSVEP\n",
    "from moabb.pipelines import ExtendedSSVEPSignal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from moabb.evaluations import CrossSubjectEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom libraries\n",
    "from ncantest import data_tools\n",
    "from ncantest import processing\n",
    "from ncantest import classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from og_FeatureExtractorSSVEP import FeatureExtractorCCA as CCA\n",
    "from og_FeatureExtractorSSVEP import FeatureExtractorMSI as MSI\n",
    "from og_FeatureExtractorSSVEP import FeatureExtractorMEC as MEC\n",
    "\n",
    "# Magic command to reload libraries\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Settings\n",
    "\n",
    "Note that if the `Wang2016` is not already downloaded, it'll be downloaded the first time you run this section of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.set_config(\"MNE_DATA\", \"~/.mne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/.mne'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.get_config(\"MNE_DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and epoch data\n",
    "dataset = Wang2016()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 2 subjects to speed up during testing\n",
    "dataset.subject_list = dataset.subject_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n",
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n"
     ]
    }
   ],
   "source": [
    "data = dataset.get_data()\n",
    "eeg_channels = [\"O1\",\"Oz\",\"O2\"]\n",
    "\n",
    "# Information from dataset description\n",
    "nsubjects = len(data)\n",
    "# labels_dict = {\"13\":0, \"17\":2, \"21\":1}  # The order is changed because the labels in the dataset are incorrect\n",
    "# stimulus_freqs = [int(f) for f in labels_dict.keys()]\n",
    "\n",
    "stimulus_freqs = [float(freq) for freq in dataset.event_id.keys()]  # Stimulus frequencies [Hz]\n",
    "srate = data[1][\"0\"][\"0\"].info['sfreq'] # Sampling rate [Hz]\n",
    "tmin = 0.5  # Time of start of SSVEP stimulus [sec]\n",
    "tmax = 5.5  # Time of end of SSVEP stimulus [sec]\n",
    "\n",
    "# Classifier settings\n",
    "# - Create CCA subbands like in Chen et al. (2015) paper\n",
    "first_column = np.arange(1, 11) * 8\n",
    "second_column = np.full(10, 88)\n",
    "cca_subbands = np.column_stack((first_column, second_column))\n",
    "harmonic_count = 2\n",
    "classifiers = [\"fbCCA\", \"MSI\", \"MEC\", \"RG_logreg\"]\n",
    "\n",
    "# Create an empty dataframe to store the accuracies\n",
    "accuracy_df = pd.DataFrame(\n",
    "    index = np.arange(0, nsubjects),\n",
    "    columns = classifiers\n",
    "    )\n",
    "accuracy_df.index.name = \"Subject\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate epochs\n",
    "\n",
    "From the raw recording datasets, create the EEG epochs using just the periods where the SSVEP stimulus was active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate data\n",
    "epochs_list = [None] * len(data)\n",
    "events_list = [None] * len(data)\n",
    "\n",
    "# Obtain epochs and events\n",
    "for s, subject in data.items():\n",
    "    [events_list[s-1], epochs_list[s-1]] = data_tools.moabb_events_to_np(\n",
    "        mne_raw = subject[\"0\"][\"0\"],\n",
    "        tmin = tmin,\n",
    "        tmax = tmax,\n",
    "        events_dict = dataset.event_id,\n",
    "        chans = eeg_channels\n",
    "        )\n",
    "    \n",
    "# Convert lists to np.ndarrays\n",
    "# eeg_channels = data[1][\"0\"][\"0\"].ch_names\n",
    "epochs_np = np.float32(np.array(epochs_list))\n",
    "events_np = np.array(events_list[0][:,2]) - 1   # The `-1` is to make the labels start at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "### Riemmanian geometry + logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm_fb = FilterBankSSVEP(\n",
    "    filters = None,\n",
    "    n_classes = 10,\n",
    "    tmin = tmin,\n",
    "    tmax = tmax,\n",
    "    channels = eeg_channels,\n",
    ")\n",
    "\n",
    "# paradigm = SSVEP(\n",
    "#     fmin = 6,\n",
    "#     fmax = 90,\n",
    "#     n_classes = 5,\n",
    "#     tmin = tmin,\n",
    "#     tmax = tmax,\n",
    "# )\n",
    "\n",
    "pipeline_rg = {}\n",
    "pipeline_rg[\"RG+LogReg\"] = make_pipeline(\n",
    "    ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    ")\n",
    "\n",
    "evaluation_rg = CrossSubjectEvaluation(\n",
    "    paradigm = paradigm_fb,\n",
    "    datasets = dataset,\n",
    "    overwrite = False\n",
    ")\n",
    "\n",
    "accuracy_rg = evaluation_rg.process(pipeline_rg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df[\"RG_logreg\"] = accuracy_rg[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing code, might have to be removed\n",
    "# Preallocate data\n",
    "# rg_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "# # Classify all epochs per subject\n",
    "# for s, subject in enumerate(epochs_np):\n",
    "#     rg_predictions = classification.fb_rg_logreg(\n",
    "#         eeg_data = subject,\n",
    "#         stim_freqs = stimulus_freqs,\n",
    "#         eeg_channels = eeg_channels, \n",
    "#         srate = srate,\n",
    "#         labels = events_np,\n",
    "#         )\n",
    "    \n",
    "#     rg_accuracies[s] = accuracy_score(events_np, rg_predictions)\n",
    "\n",
    "# # Store accuracies in dataframe\n",
    "# accuracy_df['RG_logreg'] = rg_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Testing code, might have to be removed\n",
    "# rg_accuracies = np.zeros(nsubjects)\n",
    "# for [s, subject] in enumerate(epochs_np):\n",
    "#     rg_predictions = classification.rg_logreg(\n",
    "#         eeg_data = subject,\n",
    "#         labels = events_np,\n",
    "#         )\n",
    "    \n",
    "#     rg_accuracies[s] = accuracy_score(events_np, rg_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fbCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prototype and preallocate data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cca \u001b[38;5;241m=\u001b[39m \u001b[43mCCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m cca_accuracies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(nsubjects)\n\u001b[1;32m      5\u001b[0m cca\u001b[38;5;241m.\u001b[39msetup_feature_extractor(\n\u001b[1;32m      6\u001b[0m     harmonics_count \u001b[38;5;241m=\u001b[39m harmonic_count,\n\u001b[1;32m      7\u001b[0m     targets_frequencies \u001b[38;5;241m=\u001b[39m stimulus_freqs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     subbands \u001b[38;5;241m=\u001b[39m cca_subbands\n\u001b[1;32m     12\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-macos/og_FeatureExtractorSSVEP/featureExtractorCCA.py:29\u001b[0m, in \u001b[0;36mFeatureExtractorCCA.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass constructor\u001b[39m\u001b[38;5;124m\"\u001b[39m            \n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# If set to True, the feature extraction method only returns\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# the maximum correlation coefficient.  Otherwise, the class\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# returns k correlation coefficients, where k is the minimum of\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# of the template signal rank and signal rank.  Most studies use\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# only the maximum.  Thus, the default value is True. \u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_correlation_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-macos/og_FeatureExtractorSSVEP/featureExtractorTemplateMatching.py:18\u001b[0m, in \u001b[0;36mFeatureExtractorTemplateMatching.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Setting all attributes to valid initiali values\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Hold the pre-computed template signals for SSVE.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# This is a 3D array, with dimensions of [number of targets, 2*Nh, \u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# number of samples].  Each target has a unique template signal that \u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# consistes of a linear combination of 2*Nh sinusoidal signals, where. \u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Nh is the number of harmonics.  For each harmonic a (sine, cosine)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# pair is computed, hence the midle dimension has the size of 2*Nh.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate_signal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-macos/og_FeatureExtractorSSVEP/featureExtractor.py:152\u001b[0m, in \u001b[0;36mFeatureExtractor.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_selection_info_bundle \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# A Boolean flag to instruct whether to use GPU or not.  \u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# When set to false, no GPU is used.  When set to True, a GPU is used. \u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_gpu\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# The maximum number of signals/channel selections that are \u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# processed together.  Increasing the batch size helps with \u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# parallelization but it also increases memory requirements. \u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Work/TengenToppa/GitHub/sherpaNet/SSVEP-toolbox-macos/og_FeatureExtractorSSVEP/featureExtractor.py:1204\u001b[0m, in \u001b[0;36mFeatureExtractor.use_gpu\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m   1201\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set use_gpu. use_gpu flag must either True or False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1204\u001b[0m     flag \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool8\u001b[49m(flag)\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m(\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit(message)\n",
      "File \u001b[0;32m~/Applications/miniforge3/envs/ssvep-moabb/lib/python3.10/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool8'"
     ]
    }
   ],
   "source": [
    "# Prototype and preallocate data\n",
    "cca = CCA()\n",
    "cca_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "cca.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1],\n",
    "    filter_order = 12,\n",
    "    subbands = cca_subbands\n",
    "    )\n",
    "    \n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    cca_features = cca.extract_features(subject)\n",
    "    cca_predictions = np.argmax(np.max(np.squeeze(cca_features), axis=1), axis=1)\n",
    "    cca_accuracies[s] = accuracy_score(events_np, cca_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_df[\"fbCCA\"] = cca_accuracies\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7625    , 0.83333333])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, subject in enumerate(epochs_np):\n",
    "    print(s)\n",
    "    # print(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_features = cca.extract_features(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cca_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_features[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.squeeze(cca_features)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.max(a, axis=1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.argmax(b, axis=1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cca_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype and preallocate data\n",
    "mec = MEC()\n",
    "mec_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "mec.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1]\n",
    ")\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    mec_features = mec.extract_features(subject)\n",
    "    mec_predictions = np.argmax(np.squeeze(mec_features), axis=1)\n",
    "    mec_accuracies[s] = accuracy_score(events_np, mec_predictions)\n",
    "\n",
    "accuracy_df[\"MEC\"] = mec_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype and preallocate data\n",
    "msi = MSI()\n",
    "msi_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "msi.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1]\n",
    ")\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    msi_features = msi.extract_features(subject)\n",
    "    msi_predictions = np.argmax(np.squeeze(msi_features), axis=1)\n",
    "    msi_accuracies[s] = accuracy_score(events_np, msi_predictions)\n",
    "\n",
    "accuracy_df[\"MSI\"] = msi_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['fbCCA', 'MSI', 'MEC', 'RG_logreg']\n",
    "\n",
    "# stimulus_accuracy = accuracy_df[accuracy_df[\"Stimulus\"]==stimulus]\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\n",
    "sns.stripplot(\n",
    "    data=accuracy_df,\n",
    "    ax=ax,\n",
    "    jitter=True,\n",
    "    alpha=0.5,\n",
    "    zorder=1,\n",
    "    palette=\"Set1\",\n",
    ")\n",
    "sns.pointplot(data=accuracy_df, ax=ax, palette=\"Set1\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\"fbCCA\", \"MSI\", \"MEC\", \"RG_logreg\"]\n",
    "# accuracy_df[classifiers[0]] = accuracy_rg[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x2 subplot grid\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "sns.boxplot(\n",
    "    data = accuracy_df[classifiers],\n",
    "    ax = ax,\n",
    "    color = \"black\",\n",
    "    boxprops=dict(facecolor='none'),\n",
    "    # fill = False,\n",
    "    width = 0.5,\n",
    "    linewidth = 1   \n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    data = accuracy_df[classifiers],\n",
    "    ax = ax,\n",
    "    jitter = 0.15,\n",
    "    alpha = 0.9,\n",
    "    zorder = 1,\n",
    "    palette = \"Set1\",\n",
    ")\n",
    "\n",
    "ax.set_ylim(-0.05, 1.05) \n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "# ax.set_xlabel(\"Classifier\")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "fig.savefig(\"figures\\\\moabb_boxplot_comparison.svg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "\n",
    "if save_results:\n",
    "    accuracy_df.to_csv(\"results_ncan_moabb.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
