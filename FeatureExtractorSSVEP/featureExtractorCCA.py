# featureExtractorCCA.py
"""
Feature extraction method using correlation coefficient analysis.
Chen, Xiaogang, et al. "Filter bank canonical correlation analysis
for implementing a high-speed SSVEP-based brainâ€“computer interface.
Journal of neural engineering 12.4 (2015): 046008.
"""

from .featureExtractorTemplateMatching import FeatureExtractorTemplateMatching
import mlx.core as mx  # Main MLX library

class FeatureExtractorCCA(FeatureExtractorTemplateMatching):
    """Implementation of feature extraction using CCA"""
    
    def __init__(self):
        "Class constructor"            
        super().__init__()

        # If set to True, the feature extraction method only returns
        # the maximum correlation coefficient.  Otherwise, the class
        # returns k correlation coefficients, where k is the minimum of
        # of the template signal rank and signal rank.  Most studies use
        # only the maximum.  Thus, the default value is True. 
        self.max_correlation_only = True
     
    def setup_feature_extractor(
            self, 
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=None,
            max_correlation_only=True,
            embedding_dimension=0,
            delay_step=0,
            filter_order=0,
            filter_cutoff_low=0,
            filter_cutoff_high=0,
            voters_count=1,
            random_seed=0,
            use_gpu=False,
            max_batch_size=16,
            explicit_multithreading=0,
            samples_count=0):
        """
        Setup the feature extractor parameters CCA.
        
        Mandatory Parameters:
        -------------------------------------
        harmonics_count: The number of harmonics to be used in constructing
        the template signal.  This variable must be a positive integer 
        number (typically a value from 3 to 5).  
        
        targets_frequencies: The stimulation freqeuency of each target.  
        This must be a 1D array,  where the first element is the stimulation
        frequency of the first target, the second element is the stimulation
        frequency of the second target, and so on.  The length of this array
        indicates the number of targets.  The user must determine the 
        targets_frequencies but the number of targets (targets_count) is 
        extracted automatically from the length of targets_frequencies. 
        
        sampling_frequency: The sampling rate of the signal 
        (in samples per second).  It must be a real positive value. 
                
        Optional Parameters:
        --------------------        
        embedding_dimension: This is the dimension of time-delay embedding. 
        This must be a non-negative integer.  If set to zero, no time-delay
        embedding will be used.  If there are E electrodes and we set the 
        embedding_dimension to n, the class expands the input signal as if we
        had n*E channels.  The additional channels are generated by shift_left
        operator. The number of samples that we shift each signal is 
        controlled by delay_step.  Embedding delays truncates the signal. 
        Make sure the signal is long enough. 
        
        delay_step: The number of samples that are shifted for each delay
        embedding dimension.  For example, assume we have ten channels, 
        embedding_dimension is two, and delay_step is three.  In this case, the
        class creates 30 channels.  The first ten channels are the original
        signals coming from the ten electrodes.  The second ten signals are
        obtained by shifting the origianl signals by three samples.  The third
        ten signals are obtained by shifting the original signals by six 
        samples.  The signals are truncated accordingly. 
        
        filter_order: The order of the filter used for filtering signals before
        analysis.  If filter_order is zero (the default value), no filtering
        is performed.  Otherwise, the class creates a filter of order 
        filter_order.  This must be positive integer. 
        
        cutoff_frequency_low: The first cutoff frequency of the bandpass 
        filter.  This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        cutoff_frequency_high: The second cutoff frequency of the bandpass
        filter. This must be a single real positive number.  If filter_order
        is zero, this attribute is ignored.  
        
        subbands: This is the primary way to instruct the classifier whether 
        to use filterbank or not.  The default value is None.  If set to None, 
        the classifier uses none-fitlerbank implementation.  To use
        filterbanks, subbands must be set to a 2D array, whith exactly two 
        columns.  Each row of this matrix defines a subband with two 
        frequencies provided in two columns.  The first column is the first
        cutoff frequency and the second column is the second cutoff frequency
        of that subband.  Filterbank filters the signal using a bandpass
        filter with these cutoff frequencies to obtain a new subband.  The
        number of rows in the matrix defines the number of subbands. All
        frequencies must be in Hz.  For each row, the second column must
        always be greater than the first column. 
        
        voters_count: The number of electrode-selections that are used for
        classification.  This must be a positive integer.  This is the 
        same as the number of voters.  If voters_count is larger that the 
        cardinality of the power set of the current selected electrodes, 
        then at least one combination is bound to happen more than once. 
        However, because the selection is random, even if voters_count is
        less than the cardinality of the power set, repettitions are still
        possible (although unlikely). If not specified or set to 1, no 
        voting will be used. 
        
        random_seed: This parameter control the seed for random selection 
        of electrodes.  This must be set to a non-negative integer.  The 
        default value is zero.
                
        use_gpu: When set to 'True,' the class uses a gpu to extract features.
        The host must be equipped with a CUDA-capable GPU.  When set to
        'False,' all processing will be on CPU. 
        
        max_batch_size: The maximum number of signals/channel selections
        that are processed in one batch.  Increasing this number improves
        parallelization at the expense of more memory requirement.  
        This must be a single positve integer. 
        
        explicit_multithreading: This parameter determines whether to use 
        explicit multithreading or not.  If set to a non-positive integer, 
        no multithreading will be used.  If set to a positive integer, the 
        class creates multiple threads to process signals/voters in paralle.
        The number of threads is the same as the value of this variable. 
        E.g., if set to 4, the class distributes the workload among four 
        threads.  Typically, this parameter should be the same as the number
        of cores the cput has, if multithreading is to be used. 
        Multithreading cannot be used when use_gpu is set to True.
        If multithreading is set to a positive value while used_gpu is 
        set to True or vice versa, the classes raises an error and the 
        program terminates. 
        
        samples_count: If provided, the class performs precomputations that
        only depend on the number of samples, e.g., computing the template
        signal.  If not provided, the class does not perform precomputations.
        Instead, it does the computations once the input signal was provided 
        and the class learns the number of samples from the input signal. 
        Setting samples_count is highly recommended.  If the feaure extraction
        method is being used in loop (e.g., BCI2000 loop), setting this 
        parameter eliminates the need to compute the template matrix each
        time. It also helps the class to avoid other computations in each
        iteration. samples_count passed to this function must be the same 
        as the third dimension size of the signal passed to extract_features().
        If that is not the case, the template and input signal will have 
        different dimensions.  The class should issue an error in this case
        and terminate the execution. 
        """
        self.build_feature_extractor(
            harmonics_count,
            targets_frequencies,
            sampling_frequency,
            subbands=subbands,           
            embedding_dimension=embedding_dimension,
            delay_step=delay_step,
            filter_order=filter_order,
            filter_cutoff_low=filter_cutoff_low,
            filter_cutoff_high=filter_cutoff_high,
            voters_count=voters_count,
            random_seed=random_seed,
            use_gpu=use_gpu,
            max_batch_size=max_batch_size,
            explicit_multithreading=explicit_multithreading,
            samples_count=samples_count)
            
        self.max_correlation_only = max_correlation_only
                        
    def get_features(self, device):
        """Extract features using CCA"""   
        # Get the current batch of data        
        signal = self.get_current_data_batch()        
        correlations = self.canonical_correlation_reduced(signal)  

        if self.max_correlation_only:
            # np.max -> mx.max
            correlations = mx.max(correlations, axis=-1)
                   
        batch_size = self.channel_selection_info_bundle[1]
        signals_count = correlations.shape[0]//batch_size
        
        # De-bundle the results.
        # np.reshape -> mx.reshape
        correlations = mx.reshape(correlations, (
            signals_count,
            batch_size,
            self.targets_count,            
            -1))
        
        if self.max_correlation_only:
            features = correlations
        else:                
            # np.zeros -> mx.zeros
            features = mx.zeros((
                signals_count,
                batch_size,
                self.targets_count,
                self.features_count),
                dtype=mx.float32)
        
            # Copy correlations to features
            features = features.at[:, :, :, :correlations.shape[-1]].set(correlations)
        
        return features
    
    def get_features_multithreaded(self, signal):
        """Extract MSI features from a single signal"""        
        # Center the signal
        # np.mean -> mx.mean
        signal = signal - mx.mean(signal, axis=-1)[:, None]
        # Add batch dimension
        signal = signal[None, :, :]
            
        if not self.max_correlation_only:
            self.features_count = mx.minimum(
                self.electrodes_count, 2*self.harmonics_count)
            
        correlations = self.canonical_correlation_reduced(signal)  

        if self.max_correlation_only:
            correlations = mx.max(correlations, axis=-1)
                       
        # De-bundle the results.
        correlations = mx.reshape(correlations, (
            1, 
            1,
            1,
            self.targets_count,            
            -1))
        
        if self.max_correlation_only:
            features = correlations
        else:                
            # De-bundle the results.
            features = mx.zeros((
                1, 
                1,
                1,
                self.targets_count,               
                self.features_count),
                dtype=mx.float32)
        
            features = features.at[:, :, :, :, :correlations.shape[-1]].set(correlations)
        
        return features
        
    def canonical_correlation_reduced(self, signal):
        """Compute the canonical correlation between X and Y."""         
        q_template = self.q_template_handle[0]  # Using CPU only
        
        # np.transpose -> mx.transpose
        signal = mx.transpose(signal, (0, 2, 1))      
        
        # QR decomposition for signal
        # Replace numpy's qr with MLX equivalent
        q_signal = mx.linalg.qr(signal)[0]
        q_signal = mx.transpose(q_signal, (0, 2, 1))
                     
        # np.matmul -> mx.matmul
        product = mx.matmul(
            q_signal[:, None, :, :], q_template[None, :, :, :])
        
        # np.linalg.svd -> mx.linalg.svd
        r = mx.linalg.svd(product, full_matrices=False, compute_uv=False)
        
        # Clamp values
        r = mx.clip(r, 0, 1)
        
        return r
    
    def perform_voting_initialization(self, device=0):
        """Perform initialization and precomputations common to all voters"""
        # Center data
        # np.mean -> mx.mean
        self.all_signals = self.all_signals - mx.mean(self.all_signals, axis=-1)[:, :, None]     
        self.all_signals_handle = self.handle_generator(self.all_signals)
        
        # Check signal rank
        # For MLX, we'll assume full rank since rank computation is complex
        # Original numpy check removed: rank = np.linalg.matrix_rank(self.all_signals)
        
        if not self.max_correlation_only:
            self.features_count = mx.minimum(
                self.electrodes_count, 2*self.harmonics_count)
        
    def class_specific_initializations(self):
        """Perform necessary initializations"""
        # Compute templates        
        self.compute_templates()  
        
        # Center the template signal
        self.template_signal = self.template_signal - mx.mean(
            self.template_signal, axis=1)[:, None, :]
        
        # Compute Q part of QR decomposition for template
        self.q_template = mx.zeros(
            self.template_signal.shape, dtype=mx.float32)
        
        for i in mx.arange(self.targets_count):        
            self.q_template = self.q_template.at[i].set(
                mx.linalg.qr(self.template_signal[i])[0])
            
        # Create handles
        self.template_signal_handle = self.handle_generator(
            self.template_signal)
        
        self.q_template_handle = self.handle_generator(
            self.q_template)
               
    def get_current_data_batch(self):
        """Bundle all data so they can be processed together"""
        # Extract bundle information for readability
        batch_index = self.channel_selection_info_bundle[0]        
        batch_population = self.channel_selection_info_bundle[1]
        batch_electrodes_count = self.channel_selection_info_bundle[2]
        first_signal = self.channel_selection_info_bundle[3]
        last_signal = self.channel_selection_info_bundle[4]
        signals_count = last_signal - first_signal
        
        # Pre-allocate memory for the batch
        signal = mx.zeros(
            (signals_count, batch_population,
             batch_electrodes_count, self.samples_count),
            dtype=mx.float32)        
        
        selected_signals = self.all_signals_handle[0][first_signal:last_signal]
        
        # Fill the batch with selected signals
        for j in mx.arange(batch_population):
            current_selection = self.channel_selections[batch_index]
            signal = signal.at[:, j].set(selected_signals[:, current_selection, :])
            batch_index += 1
                        
        signal = mx.reshape(signal, (-1,) + signal.shape[2:])
        return signal
        
    @property
    def max_correlation_only(self):
        """Getter for max_correlation_only flag"""
        return self.__max_correlation_only
    
    @max_correlation_only.setter
    def max_correlation_only(self, flag):
        """Setter for max_correlation_only flag"""
        try:
            flag = bool(flag)
        except(ValueError, TypeError):
            self.quit("max_correlation_only flag must be Boolean.")
            
        self.__max_correlation_only = flag